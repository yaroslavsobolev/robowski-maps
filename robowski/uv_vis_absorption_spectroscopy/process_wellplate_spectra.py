"""
Utilities for spectral processing and unmixing of UV-Vis absorption spectra from well plates.

This module provides functionality for:
1. Loading spectral data from different sources (CRAIC microspectrometer, NanoDrop spectrophotometer)
2. Processing and correcting raw spectral data
3. Calibrating using reference spectra and known concentrations should be performed
    with robowski.uv_vis_absorption_spectroscopy.calibrator module instead of this one.
    Though for backward compatibility with old scripts, this module contains the methods for constructing calibration.
4. Unmixing multi-component spectra to determine individual component concentrations
5. Calculating stoichiometric relationships between products and substrates

The main workflow involves:
1. Creating a SpectraProcessor object
2. Loading spectral data from files
3. Creating calibration references using known standards (with robowski.uv_vis_absorption_spectroscopy.calibrator module instead of this module)
4. Processing unknown samples to determine component concentrations
"""

from robowski.settings import *
import logging
import pickle

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import os
import glob
import pandas as pd
from scipy.interpolate import RegularGridInterpolator
from scipy.signal import savgol_filter
from scipy import interpolate
from scipy.optimize import curve_fit
import matplotlib.ticker as mticker
import statsmodels.api as sm
import time

# matplotlib.use('Agg')
plt.ioff()

data_folder = os.environ['ROBOCHEM_DATA_PATH'].replace('\\', '/') + '/'
craic_folder = data_folder + 'craic_microspectrometer_measurements/absorbance/'

def create_folder_unless_it_exists(path):
    """
    Create a folder at the given path if it doesn't already exist.

    Parameters
    ----------
    path : str
        Directory path to create
    """
    if not os.path.exists(path):
        os.makedirs(path)


def load_msp_file(experimental_data_filename):
    """
        Load a CRAIC microspectrometer data file (.msp format) containing UV-Vis absorption spectra.

        This function reads binary spectral data files generated by CRAIC microspectrometers during
        automated well plate measurements. The .msp format contains wavelength-absorbance pairs
        for single-point measurements from specific vial positions.

        Parameters
        ----------
        experimental_data_filename : str
            Full path to the .msp file. Typical naming pattern: 'spectrum_-{file_id}.msp'
            where file_id corresponds to well scanning sequence (1-54 for standard plates).
            Example: '/path/to/craic_data/spectrum_-15.msp'

        Returns
        -------
        numpy.ndarray
            2D array with shape (n_wavelengths, 2), where:

            - Column 0: wavelengths in nm
            - Column 1: raw absorbance values (requires downstream correction for quantitative analysis)

        """
    input_spectrum = np.loadtxt(experimental_data_filename, skiprows=10,
                                delimiter='\t')
    input_spectrum = np.transpose(input_spectrum)
    return input_spectrum


def get_spectra_file_list(target_folder, prefix='spectrum_'):
    """
    Get a list of spectrum files (.MSP) extension in the target folder that match the given prefix.
    This excludes the files that have 'rep2' anywhere in their filename, because these files are
    for second repetition of the measurement in CRAIC.

    Parameters
    ----------
    target_folder : str
        Path to folder containing spectrum files
    prefix : str, optional
        Prefix of spectrum files to match, defaults to 'spectrum_'

    Returns
    -------
    list
        List of filenames (excluding any '-3D.msp' files which contain 2D maps, and file containing 'rep2' substring.
    """
    os.chdir(target_folder)
    file_list = glob.glob(f"{prefix}*.msp")
    try:
        file_list.remove(f'{prefix}-3D.msp')  # this file contains the 2D map of absorbance at single fixed wavelength
    except ValueError:
        pass
    return [filename for filename in file_list if 'rep2' not in filename]


def construct_interpolators_for_absorbance_correction(
        nd_names=(0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.2, 1.5, 1.8, 2.0, 2.5, 3.0, 3.5, 4.0),
        nd_names_used=(0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.2, 1.5, 1.8, 2.5, 3.0, 3.5, 4.0),
        microspec_folder=repo_data_path + 'uv_vis_absorption_spectroscopy/microspectrometer-calibration/2022-12-01/2-inch-nd-calibrations',
        folder_for_saving_interpolator_datasets=repo_data_path + 'uv_vis_absorption_spectroscopy/microspectrometer-calibration/2022-12-01/interpolator-dataset/'):
    """
    Construct interpolators for correcting CRAIC microspectrometer absorbance measurements.

    This function generates a wavelength-dependent correction for CRAIC microspectrometer
    absorbance measurements by comparing measurements of identical neutral density (ND)
    filters on both the CRAIC microspectrometer and the reference Agilent Cary 5000
    spectrophotometer. The Agilent instrument is considered the ground truth due to its
    higher accuracy and precision.

    The function:
    1. Loads absorbance spectra for ND filters from both instruments
    2. Applies Savitzky-Golay filtering to smooth the spectra
    3. Aligns the wavelength domains using interpolation
    4. For each wavelength, sorts the filter measurements by absorbance value
    5. Saves the aligned and sorted datasets as numpy arrays for later use

    These saved datasets can be used to create an interpolation function at each wavelength
    that maps from CRAIC absorbance values to the corresponding Agilent values, effectively
    calibrating the CRAIC instrument against the Agilent reference.

    Parameters
    ----------
    nd_names : tuple
        Complete list of neutral density filter optical densities used in Agilent measurements.
        These values correspond to column indices in the Agilent data file.
    nd_names_used : tuple
        Subset of nd_names that are actually used in the correction. This allows excluding
        certain filters that might have measurement issues.
    microspec_folder : str
        Path to the folder containing CRAIC microspectrometer measurements of ND filters.
        Each file should be named according to the filter density (e.g., "0p5.msp" for 0.5 OD).
    folder_for_saving_interpolator_datasets : str
        Path where the processed numpy arrays will be saved for later use in the correction.

    Returns
    -------
    None
        The function doesn't return values directly but saves two numpy arrays:
        - 'craic_data.npy': Array of sorted CRAIC absorbance values for each wavelength
        - 'agilent_data.npy': Array of corresponding Agilent absorbance values

    """
    microspec_absorbances = dict()

    example_data = load_msp_file(experimental_data_filename=microspec_folder +
                                                            f'/{nd_names_used[0]:.1f}'.replace('.', 'p') + '.msp')
    craic_data = [np.zeros_like(example_data[:, 1])]
    for nd_name in nd_names_used:
        data = load_msp_file(experimental_data_filename=microspec_folder + f'/{nd_name:.1f}'.replace('.', 'p') + '.msp')
        data[:, 1] = savgol_filter(data[:, 1], window_length=31, polyorder=2)
        microspec_absorbances[nd_name] = data[:, 1]
        wavelengths = data[:, 0]
        craic_data.append(data[:, 1])
    craic_data = np.stack(craic_data)

    spectrophotometer_file = repo_data_path + 'uv_vis_absorption_spectroscopy/spectrophotometer-references/' \
                             '2-inch-nd-filters/nd-filters.csv'
    df = pd.read_csv(spectrophotometer_file, skiprows=[0], nrows=451)
    wavelengths_agilent = df.loc[:, 'Wavelength (nm)']
    agilent_data = [np.zeros_like(example_data[:, 1])]
    for nd_name in nd_names_used:
        absorbances_agilent = df.loc[:, f'Abs.{nd_names.index(nd_name) + 2}']
        absorbances_agilent = savgol_filter(absorbances_agilent, window_length=7, polyorder=2)
        agilent_interpolator = interpolate.interp1d(wavelengths_agilent, absorbances_agilent)
        agilent_data.append(agilent_interpolator(wavelengths))
    agilent_data = np.stack(agilent_data)

    for wavelength_id, wavelength in enumerate(wavelengths):
        agilent_here = np.copy(agilent_data[:, wavelength_id])
        craic_here = np.copy(craic_data[:, wavelength_id])
        sorting_ids = craic_here.argsort()
        agilent_here = agilent_here[sorting_ids]
        craic_here = craic_here[sorting_ids]
        agilent_data[:, wavelength_id] = np.copy(agilent_here)
        craic_data[:, wavelength_id] = np.copy(craic_here)

    np.save(folder_for_saving_interpolator_datasets + 'craic_data.npy', craic_data)
    np.save(folder_for_saving_interpolator_datasets + 'agilent_data.npy', agilent_data)


def load_dataset_for_absorbance_correction(target_folder=repo_data_path + 'uv_vis_absorption_spectroscopy/microspectrometer-calibration/'
                                                         '2022-12-01/interpolator-dataset/'):
    craic_data = np.load(target_folder + 'craic_data.npy')
    agilent_data = np.load(target_folder + 'agilent_data.npy')
    return [craic_data, agilent_data]


def apply_correction(input_craic_spectrum, absorbance_correction_dataset):
    craic_data, agilent_data = absorbance_correction_dataset
    result = np.zeros_like(input_craic_spectrum)
    for wavelength_id in range(input_craic_spectrum.shape[0]):
        f = interpolate.interp1d(craic_data[:, wavelength_id], agilent_data[:, wavelength_id],
                                 fill_value='extrapolate')
        result[wavelength_id] = f(input_craic_spectrum[wavelength_id])
    return result


def well_id_to_file_id(well_id):
    """
    Convert well ID to file ID based on the scanning pattern of the microspectrometer.

    The microspectrometer scans from the bottom right corner. Each scan line goes up.
    The next scan line is to the left of the previous one. Well ID is counted from the
    top left corner in left-to-right lines, with each next line below the previous one.

    Parameters
    ----------
    well_id : int
        Well ID (0-based, counted from top left in left-to-right, top-to-bottom pattern)

    Returns
    -------
    int
        File ID (1-based, corresponding to the scan sequence numbering)
    """
    # well_id to i,j. Index i is left-to-right. Index j is top-to-bottom. Both start from zero.
    j = well_id // 9
    i = well_id % 9

    # i,j to file_id
    file_id = (8 - i) * 6 + (5 - j) + 1  # plus one because file id is counted from one, not from zero
    return file_id


def load_raw_msp_by_id(plate_folder, well_id, prefix='spectrum_', suffix=''):
    """
    Load a raw microspectrometer data file for a specific well ID.

    Parameters
    ----------
    plate_folder : str
        Path to the folder containing spectrum files
    well_id : int
        Well ID to load
    prefix : str, optional
        Prefix of spectrum files, defaults to 'spectrum_'
    suffix : str, optional
        Suffix to add to the filename, defaults to ''

    Returns
    -------
    numpy.ndarray
        2D array with shape (n_wavelengths, 2), where the first column contains
        wavelengths (nm) and the second column contains absorbance values
    """
    data = load_msp_file(plate_folder + prefix + f'-{well_id_to_file_id(well_id)}{suffix}.msp')
    return data


def diluted_vials_only(list_of_vials_on_plate):
    """
    Returns the indices of diluted vials on the plate.

    Every second row of the plate was not filled with reaction mixtures and is
    later used to hold a diluted reaction mixture.

    Parameters
    ----------
    list_of_vials_on_plate : array-like
        List or array of data for all vials on the plate

    Returns
    -------
    array-like
        Subset of the input containing only the vials that are diluted
    """
    return list_of_vials_on_plate[[i + j for i in [9, 27, 45] for j in range(9)]]


def create_spectrum_mask(wavelength_indices, target_spectrum, cut_from, cut_to=None,
                         upper_limit_of_absorbance=0.95,
                         artefactogenic_upper_limit_of_absorbance=1.5):
    """
    Create a comprehensive boolean mask for spectrum fitting by combining multiple quality criteria.

    This function generates a mask that excludes problematic spectral regions from calibration
    fitting, ensuring robust coefficient determination by including only high-quality data where
    the Beer-Lambert relationship holds and instrumental artifacts are minimal.

    Each masking criterion addresses specific instrumental limitations:

    - **cut_from**: Removes noisy short-wavelength regions where lamp intensity is low and detector sensitivity varies
    - **cut_to**: Removes long-wavelength regions with negligible absorption signal, which does not contribute to the fitting/unmixing anything but noise
    - **upper_limit_of_absorbance**: Prevents fitting in non-linear regime where Beer-Lambert law breaks down
    - **artefactogenic_upper_limit_of_absorbance**: Excludes detector artifacts caused by insufficient photon flux reaching the detector of the spectrophotometer

    Specifically, the function applies criteria sequentially using logical AND operations:

    1. wavelength_indices > cut_from
    2. wavelength_indices < cut_to (if specified)
    3. target_spectrum < upper_limit_of_absorbance
    4. Artifact-free regions from `create_artifact_mask()`

    Parameters
    ----------
    wavelength_indices : numpy.ndarray
        Array of wavelength indices (0-based integers) corresponding to the spectrum.
        Shape (n_wavelengths,) typically spanning 0 to 380 for NanoDrop measurements.
    target_spectrum : numpy.ndarray
        Measured absorbance spectrum to be masked. Shape (n_wavelengths,) with
        absorbance values at each wavelength point.
    cut_from : int
        Minimum wavelength index for analysis. Wavelengths below this index are excluded
        to avoid noisy blue-end regions where instrumental artifacts dominate.
    cut_to : int or None
        Maximum wavelength index for analysis. If None, no upper wavelength limit is applied.
        Used to exclude red-end regions with minimal signal contribution.
    upper_limit_of_absorbance : float
        Maximum absorbance value for inclusion in fitting. Points above this threshold
        are masked to avoid non-linear Beer-Lambert behavior and concentration-dependent
        matrix effects.
    artefactogenic_upper_limit_of_absorbance : float
        Absorbance threshold for detecting instrumental artifacts. Regions where absorbance
        exceeds this value indicate insufficient light transmission and unreliable measurements.

    Returns
    -------
    mask : numpy.ndarray
        Boolean array indicating which wavelengths pass all quality criteria.
        Shape (n_wavelengths,) where True indicates wavelengths suitable for fitting
        and False indicates problematic regions to be excluded.

    """
    mask = wavelength_indices > cut_from
    if cut_to is not None:
        mask = np.logical_and(mask, wavelength_indices < cut_to)
    mask = np.logical_and(mask, target_spectrum < upper_limit_of_absorbance)

    # Exclude artifact-contaminated regions
    artifact_mask = create_artifact_mask(
        wavelength_indices, target_spectrum, artefactogenic_upper_limit_of_absorbance
    )
    mask = np.logical_and(mask, artifact_mask)

    return mask


def create_artifact_mask(wavelength_indices, target_spectrum,
                        artefactogenic_upper_limit_of_absorbance):
    """
    Create a mask that excludes wavelength regions contaminated by spectrophotometer artifacts.

    This function identifies and masks wavelength regions where instrumental artifacts
    occur due to insufficient light transmission reaching the detector. When absorbance
    values become very high, the spectrophotometer generates random but string spectral features that
    contaminate the measurement rather than reflecting genuine sample absorption.
    The artifacts typically begin at shorter (bluer) wavelengths where sample absorption
    is strongest, then extend toward longer wavelengths as overall absorbance increases.

    The masking strategy:

    1. **Find artifact boundary**: Locate the highest wavelength where absorbance exceeds the threshold
    2. **Mask contaminated region**: Exclude all wavelengths at and below this boundary
    3. **Preserve clean data**: Keep only wavelengths above the artifact boundary

    Parameters
    ----------
    wavelength_indices : numpy.ndarray
        Array of wavelength indices (0-based integers) corresponding to the spectrum.
        Shape (n_wavelengths,) typically spanning the full NanoDrop measurement range.
    target_spectrum : numpy.ndarray
        Measured absorbance spectrum to analyze for artifacts. Shape (n_wavelengths,)
        with absorbance values at each wavelength point.
    artefactogenic_upper_limit_of_absorbance : float
        Absorbance threshold above which instrumental artifacts are generated.
        Typical value is 1.5 for NanoDrop measurements.

    Returns
    -------
    artifact_mask : numpy.ndarray
        Boolean array indicating which wavelengths are free from artifacts.
        Shape (n_wavelengths,) where True indicates usable wavelengths and
        False indicates artifact-contaminated regions to be excluded.

    """
    artifact_indices = np.where(target_spectrum > artefactogenic_upper_limit_of_absorbance)[0]
    if len(artifact_indices) == 0:
        largest_artifact_index = -1
    else:
        largest_artifact_index = np.max(artifact_indices)

    artifact_mask = wavelength_indices > largest_artifact_index
    return artifact_mask


class SpectraProcessor:
    """
    Process and analyze UV-Vis absorption spectra from microspectrometers and spectrophotometers.

    This class provides a unified interface for processing measured optical absorption spectra
    and performing quantitative analysis through spectral unmixing.

    **Core capabilities:**

    1. Unified interface for loading data from different spectrophotometers (CRAIC or NanoDrop)
    2. Applies wavelength-dependent corrections for CRAIC data
    3. Intelligent exclusion of artifact-prone spectral regions
    4. Single-spectrum unmixing: Determines component concentrations from single spectrum
    5. Multi-spectrum unmixing: Advanced algorithm using spectra at multiple dilutions of same parent sample for enhanced accuracy.

    **Typical steps for using these module** are as follows. First, initialize the SpectraProcessor.
    Then, using the separately measured spectra of pure substances at various concentrations, calibrate these spectra
    against concentration for each substance that may be present in the reaction mixture.
    This is done with the help `perform_calibration()` method from `calibrator.py` module.
    Next, load spectra of reaction mixtures (usually measured in batches of well/vial plates, 54 vials per plate in our case).
    Finally, Perform unmixing with `spectrum_to_concentration()` or `multispectrum_to_concentration()` for each reaction mixture

    From the programming perspective, the original raison d'être of this class is to store
    the correct the CRAIC data immediately upon loading and to store the settings and calibration
    data needed for this correction. If not for this, this module could have been written in a purely
    functional style, without the need for a class.

    Attributes
    ----------
    absorbance_correction_dataset : list
        CRAIC-to-Agilent correction data [craic_data, agilent_data] from neutral density
        filter calibrations. Used to align CRAIC measurements with reference standards.
    spectrum_data_type : str
        Instrument type identifier ('craic' or 'nanodrop'). Determines masking thresholds
        and wavelength ranges for different instrument characteristics.
    nanodrop_lower_cutoff_of_wavelengths : float
        Minimum wavelength (nm) for NanoDrop data processing. Typically, 220 nm or 250 nm to
        exclude noisy blue-end regions where lamp intensity is low.
    nanodrop_upper_cutoff_of_wavelengths : float
        Maximum wavelength (nm) for NanoDrop data processing. Typically, 600 nm to
        exclude red-end regions with negligible absorption signal.
    thresh_w_indices : list
        Wavelength indices for interpolating absorbance masking thresholds. Only used for CRAIC data.
    thresh_as : list
        Absorbance threshold values corresponding to thresh_w_indices. Only used for CRAIC data.
    use_instrumental_sigmas : bool
        Whether to apply instrument-specific uncertainty models during fitting.
        When True, uses wavelength and absorbance-dependent error estimates from
        empirical residual analysis.
    sigma_interpolator : callable
        Bivariate function σ(wavelength, absorbance) providing measurement uncertainty
        estimates. Created from residual analysis of calibration measurements.
    substrates : tuple
        Chemical substrate names for stoichiometric constraint enforcement.
        Example: ('methoxybenzaldehyde', 'ethyl_acetoacetate', 'ammonium_acetate')
    df_stoich : pandas.DataFrame
        Stoichiometric coefficient table linking products to required substrate consumption.
        Used in `obey_stoichiometric_inequalities` mode to prevent unphysical solutions.

    Notes
    -----
    **Required corrections depend on the spectrophotometer used:**

    - CRAIC microspectrometer: Wavelength-dependent correction against Agilent standards
    - NanoDrop spectrophotometers: No correction needed. Empirical uncertainty models are derived from residuals obtained during calibration procedure.
    - Agilent Cary 5000: Used as reference standard (no correction needed)

    **Exclusion of problematic spectral regions:**

    - **Wavelength range limiting**: `cut_from` and `cut_to` crop the wavelength range to exclude noisy or uninformative regions
    - **Absorbance ceiling**: `upper_limit_of_absorbance` prevents fitting in regions deviating from the Beer-Lambert law
    - **Spectrometer artifacts**: `artefactogenic_upper_limit_of_absorbance` threshold is used to remove artefacts of the spectrophotometer

    **Advantages of multi-spectral unmixing:**

    Using multiple dilutions of the same sample provides:

    - Extended dynamic range for weak and strong absorption bands coexisting in the same spectrum
    - Built-in validation through dilution factor consistency
    - Improved precision for trace components

    Examples
    --------
    Configuring for NanoDrop with custom wavelength range::

        >>> sp = SpectraProcessor(
        ...     folder_with_correction_dataset='path/to/correction/',
        ...     spectrum_data_type='nanodrop'
        ... )
        >>> sp.nanodrop_lower_cutoff_of_wavelengths = 220
        >>> sp.nanodrop_upper_cutoff_of_wavelengths = 600
    """

    def __init__(self, folder_with_correction_dataset, spectrum_data_type='craic',
                 sigma_interpolator_filename=f'{data_folder}nanodrop-spectrophotometer-measurements/'
                                             f'nanodrop_errorbar_folder_2024-03-16/bivariate_spline_interpolator.pkl',
                 filepath_of_csv_stoichiometry_table='BPRF/misc/Hnamesstechiometry3.csv',
                 substrates = ('methoxybenzaldehyde', 'ethyl_acetoacetate', 'ammonium_acetate')):
        """
        Initialize the SpectraProcessor with correction dataset and parameters.

        Parameters
        ----------
        folder_with_correction_dataset : str
            Path to the folder containing absorbance correction data (craic_data.npy and agilent_data.npy)
        spectrum_data_type : str, optional
            Type of spectral data ('craic' by default)
        sigma_interpolator_filename : str, optional
            Path to the pickle file containing the uncertainty interpolator
        filepath_of_csv_stoichiometry_table : str, optional
            Path to the CSV file with stoichiometric information
        substrates : tuple, optional
            Names of substrate chemicals
        """
        self.absorbance_correction_dataset = load_dataset_for_absorbance_correction(
            target_folder=folder_with_correction_dataset)
        self.spectrum_data_type = spectrum_data_type

        self.nanodrop_lower_cutoff_of_wavelengths = 250
        self.nanodrop_upper_cutoff_of_wavelengths = 600

        if spectrum_data_type == 'craic':
            self.thresh_w_indices = [0, 25, 127, 2000]
            self.thresh_as = [0.67, 0.75, 1.6, 1.6]
        elif spectrum_data_type == 'nanodrop':
            self.thresh_w_indices = [0, 2000]
            self.thresh_as = [1.0, 1.0]
        else:
            print(f"Unknown spectrum data type: {spectrum_data_type}. Disabling the absorbance thresholds.")
            self.thresh_w_indices = [0, 20000]
            self.thresh_as = [100.0, 100.0]


        self.lower_limit_of_absorbance = 0
        self.use_instrumental_sigmas = False
        with open(sigma_interpolator_filename, 'rb') as f:
            self.sigma_interpolator = pickle.load(f)

        # uncertainty associated with stoichiometric overspending ratio
        self.uncertainty_of_stoichiometric_overspending_ratio = 0.1

        self.filepath_of_csv_stoichiometry_table = filepath_of_csv_stoichiometry_table
        self.substrates = substrates
        if self.filepath_of_csv_stoichiometry_table is not None:
            self.load_df_stoich()

    def load_df_stoich(self):
        """
        Load the stoichiometry dataframe from the CSV file.

        This method reads the stoichiometric coefficients table from the specified CSV file. Adds
        rows for each substrate. with a 1 in the column corresponding to the substrate
        and 0s in all other substrate columns.
        """
        self.df_stoich = pd.read_csv(data_folder + self.filepath_of_csv_stoichiometry_table)
        # substrates = ['methoxybenzaldehyde', 'ethyl_acetoacetate', 'ammonium_acetate']

        for i, s in enumerate(self.substrates):
            # add row with string s in 'Names', string f'SUB{i}' in Short_names column, number 1 in the column called s and zeros in other columns
            dict_to_add = {'Names': s, 'Short_names': f'SUB{i}', s: 1}
            dict_to_add.update({x: 0 for x in self.substrates if x != s})
            self.df_stoich = self.df_stoich.append(dict_to_add, ignore_index=True)

    def load_nanodrop_csv_for_one_plate(self, plate_folder,
                                        ):
        """
        Load and preprocess NanoDrop spectrophotometer data from CSV files.

        Reads CSV files generated by NanoDrop spectrophotometers, applies wavelength
        filtering, and handles UUID-tagged column names for experiment tracking.

        Note that in the specific case of NanoDrop spectrophotometer, the output spectrum may contain wavelengths
        from 190 nm to 220 nm, but sometimes it does not: it varies from sample to sample. The guaranteed wavelength
        range is from 220 nm upwards. For consistent workflow, the wavelengths below 220 nm are removed upon loading
        the data from file.

        Parameters
        ----------
        plate_folder : str
            Path to the NanoDrop CSV file containing spectral measurements.

        Returns
        -------
        pandas.DataFrame
            Processed DataFrame with 'wavelength' column and numbered sample columns ('0', '1', '2', ...).
            Filtered to wavelength range between nanodrop_lower_cutoff_of_wavelengths
            and nanodrop_upper_cutoff_of_wavelengths.

        Notes
        -----
        Handles both standard column names ('0', '1', '2') and UUID-enhanced names
        ('0_4BhYCtsRm6MY7wqCRnBh43') by removing everything after '_'.
        """
        nanodrop_df = pd.read_csv(plate_folder)

        # rename first column to "wavelength" and make it float type
        nanodrop_df = nanodrop_df.rename(columns={nanodrop_df.columns[0]: "wavelength"})

        # remove rows where wavelength is lower than nanodrop_lower_cutoff_of_wavelengths
        nanodrop_df = nanodrop_df[nanodrop_df["wavelength"] >= self.nanodrop_lower_cutoff_of_wavelengths]

        # remove rows where wavelength is higher than nanodrop_upper_cutoff_of_wavelengths
        nanodrop_df = nanodrop_df[nanodrop_df["wavelength"] <= self.nanodrop_upper_cutoff_of_wavelengths]

        nanodrop_df["wavelength"] = nanodrop_df["wavelength"].astype(float)

        # Remove underscore from the column names and everything after it.
        # This is because Yankai Jia has, at some point in time,
        # added the UUID of each comdition into the column names -- a good idea, because
        # it allows to cross-validate the relation between spectra and the list of conditions.
        nanodrop_df.columns = nanodrop_df.columns.str.split('_').str[0]

        return nanodrop_df


    def load_single_nanodrop_spectrum(self, plate_folder, well_id):
        """
        Loads the Nanodrop spectrum for a single well.

        The code can also process the nanodrop's CSV files whose nanodrop column names are, for instance, like so:
        `0_4BhYCtsRm6MY7wqCRnBh43,1_iEd9wJZKzJFfF63WizGXsJ,2_bicD5pn9i6yKwsuEwLX59r,3_cHXhtGgQtdSgyBZTx6942M, ...`
        i.e. there is a UUID added after the underscore. In principle, this commit allows for any string to be can
        be added after the underscore, it will be loaded successfully by this code.

        The code retains reverse compatibility to old nanodrop's CSV files that don't contain underscores or UUIDs.

        Parameters
        ----------
        plate_folder: str
            Path to the folder with the Nanodrop measurements.
        well_id: int
            Number of the well.

        Returns
        -------
        nanodrop_spectrum: np.array
            Array with the Nanodrop spectrum.
        """
        nanodrop_df = self.load_nanodrop_csv_for_one_plate(plate_folder=plate_folder)
        wavelengths = nanodrop_df["wavelength"].to_numpy()
        # get the column whose name is equal to well_id
        absorbances = nanodrop_df[str(well_id)].to_numpy()
        nanodrop_spectrum = np.array([wavelengths, absorbances]).T
        return nanodrop_spectrum

    def load_craic_spectrum_by_id(self, plate_folder, well_id, prefix='spectrum_', do_show=False, ignore_second_repetition=False):
        """
        Load and process a CRAIC microspectrometer spectrum by well ID.

        This method loads the spectrum file, applies absorbance correction, and optionally
        applies photo-bleaching correction if a second repetition file exists.

        Parameters
        ----------
        plate_folder : str
            Path to the folder containing spectrum files
        well_id : int
            Well ID to load
        prefix : str, optional
            Prefix of spectrum files, defaults to 'spectrum_'
        do_show : bool, optional
            Whether to display plots of the spectrum, defaults to False
        ignore_second_repetition : bool, optional
            Whether to ignore second repetition files, defaults to False

        Returns
        -------
        numpy.ndarray
            2D array with wavelengths and corrected absorbance values
        """
        spectrum = load_raw_msp_by_id(plate_folder=plate_folder, well_id=well_id, prefix=prefix)

        # if the file of the same name but suffix '_rep2' exists, then load it and apply the 'zero-dose extrapolation'
        # to correct for photobleaching
        if (not ignore_second_repetition) and \
                (os.path.isfile(plate_folder + prefix + f'-{well_id_to_file_id(well_id)}_rep2.msp')):
            try:
                spectrum_rep2 = load_raw_msp_by_id(plate_folder=plate_folder, well_id=well_id, prefix=prefix,
                                                   suffix='_rep2')
                spectrum[:, 1] = spectrum[:, 1] - 0.5*(spectrum_rep2[:, 1] - spectrum[:, 1])
            except FileNotFoundError:
                pass
        if do_show:
            plt.plot(spectrum[:, 0], spectrum[:, 1])
        spectrum[:, 1] = apply_correction(spectrum[:, 1],
                                          absorbance_correction_dataset=self.absorbance_correction_dataset)
        if do_show:
            plt.plot(spectrum[:, 0], spectrum[:, 1], label='corr')
            plt.legend()
            plt.show()
        return spectrum

    def load_msp_by_id(self, plate_folder, well_id, prefix='spectrum_', do_show=False, ignore_second_repetition=False):
        """
        Load a spectrum by well ID, automatically determining the data source type.

        This is a versatile method that can load spectra from both NanoDrop and CRAIC sources.
        It determines the source type from the plate_folder path.

        Parameters
        ----------
        plate_folder : str
            Path to the folder or file containing spectral data
        well_id : int
            Well ID to load
        prefix : str, optional
            Prefix of spectrum files (for CRAIC data), defaults to 'spectrum_'
        do_show : bool, optional
            Whether to display plots of the spectrum, defaults to False
        ignore_second_repetition : bool, optional
            Whether to ignore second repetition files (for CRAIC data), defaults to False

        Returns
        -------
        numpy.ndarray
            2D array with wavelengths and absorbance values
        """

        # if plate folder contains string "nanodrop", then treat the plate_folder as path to nanodrop CSV file
        if 'nanodrop' in plate_folder:
            spectrum = self.load_single_nanodrop_spectrum(plate_folder=plate_folder, well_id=well_id)
        else: # plate_folder is a folder with CRAIC spectra. Use load_craic_spectrum_by_id and pass all args
            spectrum = self.load_craic_spectrum_by_id(plate_folder=plate_folder, well_id=well_id, prefix=prefix,
                                                      do_show=do_show, ignore_second_repetition=ignore_second_repetition)
        return spectrum


    def load_all_spectra(self, plate_folder, prefix='spectrum_-'):
        """
        Load all spectra from a plate.

        Parameters
        ----------
        plate_folder : str
            Path to the folder or file containing spectral data
        prefix : str, optional
            Prefix of spectrum files (for CRAIC data), defaults to 'spectrum_-'

        Returns
        -------
        list
            List of spectra (numpy.ndarray) for all wells
        """
        if 'nanodrop' in plate_folder:
            # load the nanodrop csv file and count the columns
            nanodrop_df = self.load_nanodrop_csv_for_one_plate(plate_folder=plate_folder)
            well_id = 0
            resulting_array = []
            while str(well_id) in nanodrop_df.columns:
                resulting_array.append(self.load_msp_by_id(plate_folder, well_id))
                well_id += 1
            # make a warning if the length of resulting array is higher than 54
            if len(resulting_array) > 54:
                logging.warning(f'Warning: the number of wells is {len(resulting_array)}, '
                             f'which is higher than 54. Check the Nanodrop file.')
            return resulting_array
        else:
            filelist = get_spectra_file_list(plate_folder)
            return [self.load_msp_by_id(plate_folder, well_id) for well_id in range(len(filelist))]


    def show_all_spectra(self, plate_folder, prefix='spectrum_-', specific_well_ids=None):
        """
        Plot all spectra from a plate.

        Parameters
        ----------
        plate_folder : str
            Path to the folder or file containing spectral data
        prefix : str, optional
            Prefix of spectrum files (for CRAIC data), defaults to 'spectrum_-'
        specific_well_ids : list or None, optional
            If specified, only plot spectra for these well IDs
        """
        for well_id, spectrum in enumerate(self.load_all_spectra(plate_folder, prefix=prefix)):
            if specific_well_ids is None or well_id in specific_well_ids:
                plt.plot(spectrum[:, 0], spectrum[:, 1], alpha=0.3, label=f'{well_id}')
            print(f'{well_id}: max {np.max(spectrum[:, 1])}, min {np.min(spectrum[:, 1])}')
        plt.ylabel('Absorbance')
        plt.xlabel('Wavelength, nm')

    def show_all_spectra_for_one_calibrant(self, calibrant_shortname, calibration_sequence_df,
                                           experiment_name, subtract_red_end=True):
        """
        Plot all spectra for a specific calibrant from a calibration sequence.

        Parameters
        ----------
        calibrant_shortname : str
            Short name of the calibrant
        calibration_sequence_df : pandas.DataFrame
            DataFrame with calibration sequence information
        subtract_red_end : bool, optional
            Whether to subtract the median of the last 10 points from the spectrum, defaults to True

        Returns
        -------
        numpy.ndarray
            The last spectrum loaded
        """
        one_calibrant_df = calibration_sequence_df.loc[calibration_sequence_df['shortname'] == calibrant_shortname]
        for index, row in one_calibrant_df.iterrows():
            spectrum = self.load_msp_by_id(
                plate_folder=data_folder + experiment_name + f"microspectrometer_data/calibration/plate-{row['plate_id']:04d}/",
                well_id=row['well_id'])
            if subtract_red_end:
                spectrum[:, 1] -= np.median(spectrum[-10:, 1])
            plt.plot(spectrum[:, 0], spectrum[:, 1], alpha=0.5,
                     label=f"{row['concentration']:.5f} M, well_id:{row['well_id']}")
        plt.legend()
        plt.show()
        return spectrum


    def load_calibration_for_one_calibrant(self, calibrant_shortname, calibration_folder, use_line_fit=False,
                                           do_savgol_filtering=False, returned_interpolator_direction='coeff_to_concentration'):
        """
        Load calibration data for a single component from precomputed calibration files

        Imports the complete calibration dataset created by the `perform_calibration` method of the `calibrator.py` 
        module, providing the reference spectrum and coefficient-to-concentration relationship needed for 
        quantitative spectral unmixing.

        Parameters
        ----------
        calibrant_shortname : str
            Short name identifier for the chemical component.
        calibration_folder : str
            Path to the root calibration directory with references/{calibrant_shortname}/ subdirectory.
        use_line_fit : bool, optional
            Whether to use linear calibration curve (y = ax) instead of interpolation. Default is False.
        do_savgol_filtering : bool, optional
            Whether to apply Savitzky-Golay smoothing to reference spectrum. Default is False.
        returned_interpolator_direction : str, optional
            Direction of interpolator: 'coeff_to_concentration' or 'concentration_to_coeff'. 
            Default is 'coeff_to_concentration'.

        Returns
        -------
        tuple
            (coeff_to_concentration_interpolator, reference_interpolator, bkg_spectrum)

            - constructed_interpolator : callable
                Function converting spectral scaling coefficients to concentrations, or vice versa,
                depending on `returned_interpolator_direction`.
            - reference_interpolator : callable  
                Function providing reference spectrum absorbance at wavelength indices
            - bkg_spectrum : numpy.ndarray
                Background spectrum for baseline subtraction, shape (n_wavelengths, 2)

        Examples
        --------
        Load calibration for analysis::

            >>> coeff_to_conc, ref_interp, bkg = sp.load_calibration_for_one_calibrant(
            ...     'methoxybenzaldehyde', 'calibration/'
            ... )
        """
        bkg_spectrum = np.load(calibration_folder + f'references/{calibrant_shortname}/bkg_spectrum.npy')

        coeffs = np.load(calibration_folder + f'references/{calibrant_shortname}/interpolator_coeffs.npy')
        concentrations = np.load(
            calibration_folder + f'references/{calibrant_shortname}/interpolator_concentrations.npy')

        if not use_line_fit:
            if returned_interpolator_direction == 'coeff_to_concentration':
                constructed_interpolator = interpolate.interp1d(coeffs, concentrations,
                                                                           fill_value='extrapolate')
            elif returned_interpolator_direction == 'concentration_to_coeff':
                constructed_interpolator = interpolate.interp1d(concentrations, coeffs,
                                                                           fill_value='extrapolate')
            else:
                raise ValueError(f"Unknown interpolator direction: {returned_interpolator_direction}. "
                                 f"Use 'coeff_to_concentration' or 'concentration_to_coeff'.")
        else:
            xs = coeffs
            ys = concentrations
            popt, pcov = curve_fit(lambda x, a: a * x, xs, ys, p0=(1))
            new_xs = np.array([0, 1.0])
            new_ys = np.array([0, popt[0]])

            if returned_interpolator_direction == 'coeff_to_concentration':
                constructed_interpolator = interpolate.interp1d(new_xs, new_ys,
                                                                           fill_value='extrapolate')
            elif returned_interpolator_direction == 'concentration_to_coeff':
                constructed_interpolator = interpolate.interp1d(new_ys, new_xs,
                                                                           fill_value='extrapolate')
            else:
                raise ValueError(f"Unknown interpolator direction: {returned_interpolator_direction}. "
                                 f"Use 'coeff_to_concentration' or 'concentration_to_coeff'.")

        ref_spectrum = np.load(calibration_folder + f'references/{calibrant_shortname}/ref_spectrum.npy')
        wavelength_indices = np.arange(ref_spectrum.shape[0])
        if do_savgol_filtering:
            ref_spectrum = savgol_filter(ref_spectrum, 7, 3)
        reference_interpolator = interpolate.interp1d(wavelength_indices, ref_spectrum, fill_value='extrapolate')
        return constructed_interpolator, reference_interpolator, bkg_spectrum


    def spectrum_to_concentration(self, target_spectrum_input, calibration_folder, calibrant_shortnames,
                                  background_model_folder,
                                  lower_limit_of_absorbance=-0.2, fig_filename='temp', do_plot=False, #lower_limit_of_absorbance=0.02
                                  upper_bounds=[np.inf, np.inf], use_line=False, cut_from=200, ignore_abs_threshold=False,
                                  cut_to = False, ignore_pca_bkg=False, return_errors=False,
                                  return_report=False): #upper_bounds=[np.inf, np.inf]
        """
        Determine component concentrations from a single absorption spectrum.

        Performs quantitative analysis by fitting a linear combination of reference spectra
        to the measured target spectrum. Standard approach when only one spectrum per sample
        is available.

        The model being fitted is:

        .. math::

            A(\lambda) = \sum_j a_j R_j(\lambda) + b_0 + b_1 \cdot \lambda + \sum_k w_k B_k(\lambda)

        where:

        - :math:`A(\lambda)` is predicted absorbance at wavelength :math:`\lambda`
        - :math:`a_j` is scaling coefficient for calibrant j (proportional to concentration)
        - :math:`R_j(\lambda)` is reference spectrum of calibrant j at wavelength :math:`\lambda`
        - :math:`b_0` is constant baseline offset (instrumental drift)
        - :math:`b_1` is linear baseline slope (wavelength-dependent drift)
        - :math:`w_k` is weight for PCA background component k
        - :math:`B_k(\lambda)` is PCA background component k at wavelength :math:`\lambda`

        The :math:`a_i` coefficients are subsequently converted to concentrations using
        the `coeff_to_concentration_interpolator` for each calibrant.
        The model includes an optional linear baseline term (:math:`b_1 \cdot \lambda`) and optionally PCA background components
        :math:`w_k B_k(\lambda)`.


        Parameters
        ----------
        target_spectrum_input : numpy.ndarray
            1D array of absorbance values for the mixture spectrum.
        calibration_folder : str
            Path to directory containing calibration data previously saved by `perform_calibration()` method of `calibrator.py` module.
        calibrant_shortnames : list of str
            Short names of components to include in analysis.
        background_model_folder : str
            Path to directory containing PCA background model files.
        lower_limit_of_absorbance : float, optional
            Minimum absorbance value for inclusion in fitting. Default -0.2, which removes artifacts manifesting as negative absorbance values.
        fig_filename : str, optional
            Base path for saving diagnostic plot. Default 'temp'.
        do_plot : bool, optional
            Whether to display interactive plots to the user during the fitting process. Default is False.
        upper_bounds : list of float, optional
            Upper concentration bounds for each calibrant. Default [np.inf, np.inf].
        use_line : bool, optional
            Whether to include linear baseline term. Default False.
        cut_from : int, optional
            Wavelength index to start analysis from. Earlier wavelengths are ignored. It is counting points from the left
            edge of the spectrum. For example, in a typical nanodrop spectrum, the first point is at 220 nm, so if you set
            cut_from=5, it will start processing from 225 nm onwards.
        ignore_abs_threshold : bool, optional
            Whether to disable absorbance threshold masking. Default False.
        cut_to : int or False, optional
            Wavelelengths with index above this integer value are ignored. If None, then all wavelengths with indices
            above cut_from are used. Useful for excluding
            the long sections of almost zero absorbance at the red end of the spectrum, which are not contributing
            anything but noise to the calibration.
        ignore_pca_bkg : bool, optional
            Whether to disable PCA background fitting. Default False.
        return_errors : bool, optional
            Whether to return uncertainty estimates. Default False. Muse not be True if return_report is True.
        return_report : bool, optional
            Whether to return detailed fitting report. Default False. Must not be True if return_errors is True.

        Returns
        -------
        list or tuple
            List of fitted concentrations, or tuple (concentrations, errors) if return_errors=True,
            of tuple(concentrations, report) if return_report=True. `report` is a dictionary with detailed fitting information:
            it contains the following keys: 'concentration_errors', 'rmse', 'LB_pvalue', 'LB_stat', `dw_statistic` for
            the errors of concentration (in same units as concentration), root-mean squared error of the fit,
            Ljung-Box p-value and statistic, and Durbon-Watson statistic, respectively. Ljung-Box statistic
            is computed at lag equal to the length of residuals divided by 5, which is largest value
            recommended by statsmodels package for Ljung-Box test. Durbin-Watson statistic is computed at lag 30 points,
            which means 30 nm in our case.
        """
        self.lower_limit_of_absorbance = lower_limit_of_absorbance

        calibrants = self.load_dictionary_of_calibrants_from_files(calibrant_shortnames, calibration_folder,
                                                                   use_linear_calibration=False)

        bkg_spectrum = calibrants[0]['bkg_spectrum']
        wavelengths = bkg_spectrum[:, 0]
        target_spectrum = target_spectrum_input - bkg_spectrum[:, 1]
        wavelength_indices = np.arange(calibrants[0]['bkg_spectrum'].shape[0])
        mask = self.mask_the_spectrum(wavelength_indices, target_spectrum, cut_from,
                                      ignore_abs_threshold=ignore_abs_threshold, cut_to=cut_to)
        background_interpolators = self.load_background_interpolators(background_model_folder, ignore_pca_bkg,
                                                                      wavelength_indices, number_of_pca_components=2)

        if len(wavelength_indices[mask]) == 0:
            print('There is no data that is usable. Returning zeros.')
            return [0 for i in range(4)]

        # MODEL
        def model_function(*args):
            """
            Spectral model function to be used by scipy.optimize.curve_fit in single-spectrum unmixing.

            Models the measured absorption spectrum as a linear combination of calibrant reference
            spectra plus instrumental baseline and weighted PCA components of background. Since it takes
            wavelength indices as the first argument, the mathematical formulation of this implementation is

            .. math::

                A(i) = \sum_j a_j R_j(i) + b_0 + b_1 \cdot i + \sum_k w_k B_k(i)

            where:

            - :math:`A(i)` is predicted absorbance at wavelength index i
            - :math:`a_j` is scaling coefficient for calibrant j. This coefficient is proportional to concentration.
            - :math:`R_j(i)` is reference spectrum of calibrant j at wavelength index i
            - :math:`b_0` is constant baseline offset (instrumental drift)
            - :math:`b_1` is linear baseline slope (wavelength-dependent drift)
            - :math:`w_k` is weight for PCA background component k
            - :math:`B_k(i)` is PCA background component k at wavelength index i

            The fitted scaling coefficients :math:`a_j` are later converted to concentrations using calibration curves.
            Parameters follow the requirements of scipy.optimize.curve_fit.


            Parameters
            ----------
            args[0] : numpy.ndarray
                Wavelength indices where spectrum should be evaluated
            args[1:-4] : float
                As many scaling coefficients as needed - one for each calibrant's reference spectrum. These will be fitted.
            args[-4:] : float
                [baseline_offset, linear_slope, pca1_weight, pca2_weight]. These will be fitted.

            Returns
            -------
            numpy.ndarray
                Predicted absorption spectrum at the input wavelength indices

            Notes
            -----
            This function accesses calibrants and background_interpolators from the enclosing scope.
            It is designed specifically as the model function to be used by curve_fit for optimization.
            """
            # Extract wavelength indices, at which the model spectrum should be evaluated
            wavelength_indices = args[0]

            # Extract fitted baseline and background parameters (last 4 fitted parameters)
            baseline_offset, linear_slope, pca1_weight, pca2_weight = args[-4:]

            # Extract fitted scaling coefficients for each calibrant (middle fitted parameters)
            calibrant_coefficients = args[1:-4]

            # Build predicted spectrum as linear combination of components
            predicted_spectrum = (
                # Core Beer-Lambert law: sum of scaled reference spectra
                    sum([calibrant_coefficients[i] * calibrants[i]['reference_interpolator'](wavelength_indices)
                         for i in range(len(calibrant_coefficients))]) +

                    # Instrumental baseline correction: constant offset + linear drift
                    baseline_offset + linear_slope * wavelength_indices +

                    # Systematic background variations captured by PCA components
                    pca1_weight * background_interpolators[0](wavelength_indices) +
                    pca2_weight * background_interpolators[1](wavelength_indices)
            )

            return predicted_spectrum

        p0 = tuple([0.5 if upper_bound is np.inf else upper_bound for upper_bound in upper_bounds] + [0] * 4)
        if use_line:
            linebounds = [-np.inf, np.inf]
        else:
            linebounds = [-1e-15, 1e-15]

        if ignore_pca_bkg:
            bkg_comp_limit = 1e-12
        else:
            bkg_comp_limit = np.inf
        bounds = ([-1e-20] * len(calibrant_shortnames) + [-np.inf, linebounds[0], -1*bkg_comp_limit, -1*bkg_comp_limit],
                  upper_bounds + [np.inf, linebounds[1], bkg_comp_limit, bkg_comp_limit])

        # FITTING OF THE MODEL
        popt, pcov = curve_fit(model_function, wavelength_indices[mask], target_spectrum[mask],
                               p0=p0, bounds=bounds)
        perr = np.sqrt(np.diag(pcov))  # errors of the fitted coefficients

        concentrations_here = [calibrants[calibrant_index]['coeff_to_concentration_interpolator'](fitted_coeff)
                               for calibrant_index, fitted_coeff in enumerate(popt[:-4])]

        ## Uncomment the following line to plot the covariance matrix of the fitted coefficients
        # self._plot_covariance_matrix(calibrant_shortnames, pcov)

        self._diagnostic_plot_of_spectrum_to_concentration_unmixing(wavelengths, wavelength_indices, target_spectrum,
                                                                    target_spectrum_input, mask, calibrant_shortnames,
                                                                    concentrations_here, model_function, popt, ignore_pca_bkg,
                                                                    fig_filename, use_line, do_plot)

        upper_confidence_limit = [
            calibrants[calibrant_index]['coeff_to_concentration_interpolator'](fitted_coeff + perr[calibrant_index])
            for calibrant_index, fitted_coeff in enumerate(popt[:-4])]
        concentration_errors = [upper_confidence_limit[i] - concentrations_here[i] for i in
                                range(len(concentrations_here))]
        if return_errors:
            # convert coefficient errors into concentration errors
            return concentrations_here, concentration_errors
        elif return_report:
            fit_report = dict()
            fit_report['concentration_errors'] = concentration_errors
            residuals_here = target_spectrum[mask] - model_function(wavelength_indices[mask], *popt)
            fit_report['rmse'] = np.sqrt(np.mean(residuals_here ** 2))
            lag = len(residuals_here) // 5
            lb_df = sm.stats.acorr_ljungbox(residuals_here, lags=[lag])
            # if lb_df is a DataFrame and its length is one
            if isinstance(lb_df, pd.DataFrame):
                if len(lb_df) == 1:
                    # Record Ljung-Box test statistics for residual autocorrelation
                    fit_report['LB_pvalue'] = lb_df.loc[lag, 'lb_pvalue']
                    fit_report['LB_stat'] = lb_df.loc[lag, 'lb_stat']
            # if lb_df is a tuple
            elif isinstance(lb_df, tuple):
                fit_report['LB_pvalue'] = lb_df[1][0]
                fit_report['LB_stat'] = lb_df[0][0]
            else:
                raise ValueError(f"Unexpected type of lb_df: {type(lb_df)}. Expected DataFrame or tuple. Maybe something wrong with the statsmodels version?")

            lag = 30 # points, which in our case means 30 nm
            fit_report['dw_statistic'] = sm.stats.stattools.durbin_watson(residuals_here[::lag])

            return concentrations_here, fit_report

        return concentrations_here


    def _plot_covariance_matrix(self, calibrant_shortnames, pcov):
        # plot covariance matrix
        plt.figure(figsize=(5, 10))
        pcov_to_plot = pcov[:len(calibrant_shortnames), :len(calibrant_shortnames)]
        plt.imshow(pcov_to_plot, vmin=-1 * max(np.abs(pcov_to_plot).flatten()),
                   vmax=max(np.abs(pcov_to_plot).flatten()),
                   cmap='RdBu_r')
        # make tick labels from calibrant_shortnames
        plt.yticks(range(len(calibrant_shortnames)), calibrant_shortnames)
        plt.xticks(range(len(calibrant_shortnames)), calibrant_shortnames, rotation=90)
        plt.colorbar(orientation='vertical', fraction=0.046)
        plt.tight_layout()
        plt.show()


    def _diagnostic_plot_of_spectrum_to_concentration_unmixing(self, wavelengths, wavelength_indices, target_spectrum,
                                                               target_spectrum_input, mask, calibrant_shortnames,
                                                               concentrations_here, func, popt, ignore_pca_bkg,
                                                               fig_filename, use_line, do_plot):
        fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True, gridspec_kw={'height_ratios': [3, 1]})
        ax = ax1
        ax.plot(wavelengths, target_spectrum_input, label='Raw data', color='grey', alpha=0.2)
        ax.plot(wavelengths, target_spectrum, label='Data minus bkg.', color='black', alpha=0.5)
        mask_illustration = np.ones_like(target_spectrum) * np.max(target_spectrum)
        mask_illustration[mask] = 0
        ax.fill_between(x=wavelengths, y1=0, y2=mask_illustration, color='yellow', alpha=0.3,
                        label='Masked data')
        ax.plot(wavelengths, func(wavelength_indices, *popt), color='r', label='Fit', alpha=0.5)
        for calibrant_index in range(len(calibrant_shortnames)):
            cpopt = [x if i == calibrant_index else 0 for i, x in enumerate(popt)]
            ax.plot(wavelengths, func(wavelength_indices, *cpopt), label=calibrant_shortnames[calibrant_index],
                    alpha=0.5)
        # make a list where only the third from the end item is the same as in popt, while the other ones are zero
        if use_line:
            cpopt = [x if i == len(popt) - 3 else 0 for i, x in enumerate(popt)]
            ax.plot(wavelengths, func(wavelength_indices, *cpopt), label='Line', alpha=0.5)
        if not ignore_pca_bkg:
            cpopt = [x if i == len(popt) - 2 else 0 for i, x in enumerate(popt)]
            ax.plot(wavelengths, func(wavelength_indices, *cpopt), label='Bkg. PC1', alpha=0.5)
            cpopt = [x if i == len(popt) - 1 else 0 for i, x in enumerate(popt)]
            ax.plot(wavelengths, func(wavelength_indices, *cpopt), label='Bkg. PC2', alpha=0.5)
        title_str = f'Concentrations:\n'
        for i in range(len(concentrations_here)):
            title_str += f'{np.array(concentrations_here)[i]:.6f} M ({calibrant_shortnames[i]})\n '
        fig1.suptitle(title_str[:-2])
        ax.set_ylabel('Absorbance')
        ax.legend()
        # Residuals subplot
        ax = ax2
        ax.plot(wavelengths[mask], target_spectrum[mask] - func(wavelength_indices[mask], *popt), color='black',
                alpha=0.5,
                label='residuals')
        ax.legend()
        ax.set_xlabel('Wavelength, nm')
        ax.set_ylabel('Absorbance')
        fig1.savefig(f"{fig_filename}.png")
        if do_plot:
            plt.show()
        else:
            plt.close(fig1)
            plt.close('all')
            plt.clf()

    def concentrations_for_one_plate(self, experiment_folder, plate_folder,
                                      calibration_folder, calibrant_shortnames, calibrant_upper_bounds,
                                     background_model_folder, do_plot=False, return_all_substances=False,
                                     cut_from = 200, cut_to=False, ignore_abs_threshold=False, ignore_pca_bkg=False):
        """
        Calculate concentrations for all wells in a plate.

        Parameters
        ----------
        experiment_folder : str
            Path to the experiment folder
        plate_folder : str
            Path to the folder or file containing spectral data
        calibration_folder : str
            Path to the folder containing calibration data
        calibrant_shortnames : list
            List of short names of the calibrants to include in the unmixing
        calibrant_upper_bounds : list
            Upper bounds for calibrant concentrations
        background_model_folder : str
            Path to the folder containing background model data
        do_plot : bool, optional
            Whether to display plots during processing, defaults to False
        return_all_substances : bool, optional
            Whether to return concentrations for all substances, defaults to False
        cut_from : int, optional
            Wavelength index to start the analysis from, defaults to 200
        cut_to : int or False, optional
            Wavelength index to end the analysis at, defaults to False
        ignore_abs_threshold : bool, optional
            Whether to ignore absorbance thresholds, defaults to False
        ignore_pca_bkg : bool, optional
            Whether to ignore PCA background components, defaults to False

        Returns
        -------
        numpy.ndarray
            Array of calculated concentrations for all wells
        """
        plate_name = plate_folder.split('/')[-1]
        create_folder_unless_it_exists(experiment_folder + 'results')
        create_folder_unless_it_exists(experiment_folder + f'results/uv-vis-fits')
        concentrations = []

        if 'nanodrop' in plate_folder:
            # load the nanodrop csv file and count the columns
            nanodrop_df = self.load_nanodrop_csv_for_one_plate(plate_folder=plate_folder)
            well_id = 0
            range_of_wells = []
            while str(well_id) in nanodrop_df.columns:
                range_of_wells.append(well_id)
                well_id += 1
            # make a warning if the length of resulting array is higher than 54
            if len(range_of_wells) > 54:
                logging.warning(f'Warning: the number of wells is {len(range_of_wells)}, '
                             f'which is higher than 54. Check the Nanodrop file.')
        else:
            range_of_wells = range(54)

        for well_id in range_of_wells:
            spectrum = self.load_msp_by_id(
                plate_folder=plate_folder,
                well_id=well_id)[:, 1]
            concentrations_here = self.spectrum_to_concentration(target_spectrum_input=spectrum,
                                                                 calibration_folder=calibration_folder,
                                                                 calibrant_shortnames=calibrant_shortnames,
                                                                 fig_filename=experiment_folder + f'results/uv-vis-fits/{plate_name}-well{well_id:02d}.png',
                                                                 do_plot=do_plot,
                                                                 background_model_folder=background_model_folder,
                                                                 upper_bounds=calibrant_upper_bounds, cut_from=cut_from,
                                                                 cut_to=cut_to,
                                                                 ignore_abs_threshold=ignore_abs_threshold,
                                                                 ignore_pca_bkg=ignore_pca_bkg)
            if return_all_substances:
                concentrations.append(concentrations_here)
            else:
                concentrations.append(concentrations_here[0])

        return np.array(concentrations)

    def multispectrum_concentrations_for_one_plate(self, experiment_folder, plate_folder_1,
                                                   plate_folder_2, dilution_factors,
                                                   calibration_folder, calibrant_shortnames, calibrant_upper_bounds,
                                                   background_model_folder, do_plot=False, return_all_substances=False,
                                                   cut_from=200, cut_to=False, ignore_abs_threshold=False,
                                                   ignore_pca_bkg=False,
                                                   return_report=False, upper_limit_of_absorbance=1000,
                                                   list_of_starting_concentration_dicts=None,
                                                   obey_stoichiometric_inequalities=True):
        """
        Calculate concentrations from multiple spectra of the same wells with different dilutions.

        This method is used when a plate has been measured twice with different dilution factors
        to capture both high and low concentration components accurately.

        Parameters
        ----------
        experiment_folder : str
            Path to the experiment folder
        plate_folder_1 : str
            Path to the first plate data
        plate_folder_2 : str
            Path to the second plate data
        dilution_factors : list
            List of dilution factors for each plate
        calibration_folder : str
            Path to the folder containing calibration data
        calibrant_shortnames : list
            List of short names of the calibrants to include in the unmixing
        calibrant_upper_bounds : list
            Upper bounds for calibrant concentrations
        background_model_folder : str
            Path to the folder containing background model data
        do_plot : bool, optional
            Whether to display plots during processing, defaults to False
        return_all_substances : bool, optional
            Whether to return concentrations for all substances, defaults to False
        cut_from : int, optional
            Wavelength index to start the analysis from, defaults to 200
        cut_to : int or False, optional
            Wavelength index to end the analysis at, defaults to False
        ignore_abs_threshold : bool, optional
            Whether to ignore absorbance thresholds, defaults to False
        ignore_pca_bkg : bool, optional
            Whether to ignore PCA background components, defaults to False
        return_report : bool, optional
            Whether to return a detailed report of the unmixing, defaults to False
        upper_limit_of_absorbance : float, optional
            Upper limit for absorbance values, defaults to 1000
        list_of_starting_concentration_dicts : list or None, optional
            List of dictionaries with starting concentrations for each well
        obey_stoichiometric_inequalities : bool, optional
            Whether to enforce stoichiometric constraints, defaults to True

        Returns
        -------
        numpy.ndarray or tuple
            Array of calculated concentrations, or tuple of (concentrations, reports) if return_report=True
        """
        if list_of_starting_concentration_dicts is None:
            list_of_starting_concentration_dicts = [None] * len(calibrant_shortnames)
        plate_name = plate_folder_1.split('/')[-1]
        create_folder_unless_it_exists(experiment_folder + 'results')
        create_folder_unless_it_exists(experiment_folder + f'results/uv-vis-fits')
        concentrations = []
        reports = []
        if 'nanodrop' in plate_folder_1:
            # load the nanodrop csv file and count the columns
            nanodrop_df = self.load_nanodrop_csv_for_one_plate(plate_folder=plate_folder_1)
            well_id = 0
            range_of_wells = []
            while str(well_id) in nanodrop_df.columns:
                range_of_wells.append(well_id)
                well_id += 1
            # make a warning if the length of resulting array is higher than 54
            if len(range_of_wells) > 54:
                logging.warning(f'Warning: the number of wells is {len(range_of_wells)}, '
                             f'which is higher than 54. Check the Nanodrop file.')
        else:
            range_of_wells = range(54)

        for well_id in range_of_wells:
            spectrum_1 = self.load_msp_by_id(
                plate_folder=plate_folder_1,
                well_id=well_id)[:, 1]
            spectrum_2 = self.load_msp_by_id(
                plate_folder=plate_folder_2,
                well_id=well_id)[:, 1]
            print(f'>>>>>>>>>>>>>>>>>> Well {well_id}')
            concentrations_here = self.multispectrum_to_concentration(
                                            target_spectrum_inputs=[spectrum_1, spectrum_2],
                                            dilution_factors=dilution_factors,
                                            calibration_folder=calibration_folder,
                                            calibrant_shortnames=calibrant_shortnames,
                                            fig_filename=experiment_folder + f'results/uv-vis-fits/{plate_name}-well{well_id:02d}.png',
                                            do_plot=do_plot,
                                            background_model_folder=background_model_folder,
                                            upper_bounds=calibrant_upper_bounds, cut_from=cut_from,
                                            cut_to=cut_to,
                                            ignore_abs_threshold=ignore_abs_threshold,
                                            ignore_pca_bkg=ignore_pca_bkg,
                                            upper_limit_of_absorbance=upper_limit_of_absorbance,
                                            return_report=return_report,
                                            starting_concentration_dict=list_of_starting_concentration_dicts[well_id],
                                            obey_stoichiometric_inequalities=obey_stoichiometric_inequalities)
            if return_report:
                concentrations_here, report = concentrations_here
                reports.append(report)

            if return_all_substances:
                concentrations.append(concentrations_here)
            else:
                concentrations.append(concentrations_here[0])

        if not return_report:
            return np.array(concentrations)
        else:
            return np.array(concentrations), reports

    def concentrations_for_all_plates(self, timepoint_id, experiment_folder,
                                      calibration_folder,
                                      calibrant_shortnames,
                                      path_to_input_compositions_csv,
                                      calibrant_upper_bounds, do_plot=False):
        """
        Calculate concentrations for all wells in all plates for a specific timepoint.

        Parameters
        ----------
        timepoint_id : int
            ID of the timepoint to process
        experiment_folder : str
            Path to the experiment folder
        calibration_folder : str
            Path to the folder containing calibration data
        calibrant_shortnames : list
            List of short names of the calibrants to include in the unmixing
        path_to_input_compositions_csv : str
            Path to the CSV file with input compositions
        calibrant_upper_bounds : list
            Upper bounds for calibrant concentrations
        do_plot : bool, optional
            Whether to display plots during processing, defaults to False

        Returns
        -------
        pandas.DataFrame
            DataFrame with calculated concentrations for all plates and wells
        """
        create_folder_unless_it_exists(experiment_folder + 'results')
        create_folder_unless_it_exists(experiment_folder + f'results/uv-vis-fits')
        input_compositions = pd.read_csv(path_to_input_compositions_csv)
        concentrations = []
        for index, row in input_compositions.iterrows():
            plate_id = index // 54
            well_id = index % 54
            print(f'{plate_id}-{well_id}')
            spectrum = self.load_msp_by_id(
                plate_folder=experiment_folder + f"microspectrometer_data/timepoint_{timepoint_id:03d}/plate-{plate_id:02d}/",
                well_id=well_id)[:, 1]
            concentrations_here = self.spectrum_to_concentration(target_spectrum_input=spectrum,
                                                                 calibration_folder=calibration_folder,
                                                                 calibrant_shortnames=calibrant_shortnames,
                                                                 fig_filename=experiment_folder + f'results/uv-vis-fits/plate{plate_id:04d}-well{well_id:02d}.png',
                                                                 do_plot=do_plot,
                                                                 upper_bounds=calibrant_upper_bounds)
            concentrations.append(concentrations_here[0])
        input_compositions[calibrant_shortnames[0]] = concentrations
        input_compositions.to_csv(
            experiment_folder + f'results/timepoint{timepoint_id:03d}-reaction_results.csv', index=False)
        return input_compositions


    def get_absorbance_at_single_wavelength_for_one_plate(self, plate_folder, wavelength=None, ref_wavelengths=None,
                                                          wavelength_id = 100, ref_wavelength_id=[500]):
        """
        Get the absorbance at a specific wavelength for all wells in a plate.

        This method calculates the difference between absorbance at the target wavelength
        and the mean absorbance at reference wavelengths.

        Parameters
        ----------
        plate_folder : str
            Path to the folder or file containing spectral data
        wavelength : float or None, optional
            Target wavelength (nm), defaults to None
        ref_wavelengths : list or None, optional
            List of reference wavelengths (nm), defaults to None
        wavelength_id : int, optional
            Target wavelength index, used if wavelength is None, defaults to 100
        ref_wavelength_id : list, optional
            List of reference wavelength indices, used if ref_wavelengths is None, defaults to [500]

        Returns
        -------
        numpy.ndarray
            Array of absorbance values for all wells
        """
        if not (wavelength is None):
            wavelengths = self.load_msp_by_id(plate_folder=plate_folder, well_id=0)[:, 0]
            wavelength_id = np.absolute(wavelengths - wavelength).argmin()
            ref_wavelength_id = [np.absolute(wavelengths - ref_wavelength).argmin() for ref_wavelength in ref_wavelengths]

        wavelengths = self.load_msp_by_id(plate_folder=plate_folder, well_id=0)[:, 0]
        print(f'Wavelength for wavelength_id is: {wavelengths[wavelength_id]}')
        for ref_wav in ref_wavelength_id:
            print(f'Reference wavelength for ref_wavelength_id is: {wavelengths[ref_wav]}')

        concentrations = []
        for well_id in range(54):
            spectrum = self.load_msp_by_id(plate_folder=plate_folder, well_id=well_id)[:, 1]
            concentrations.append(spectrum[wavelength_id] - np.mean(np.array([spectrum[ref_wav] for ref_wav in ref_wavelength_id])))
        return np.array(concentrations)


    def mask_the_spectrum(self, wavelength_indices, target_spectrum,
                          cut_from, ignore_abs_threshold=False, cut_to=False):
        """
        Apply masking to a spectrum based on wavelength range and absorbance thresholds.

        Parameters
        ----------
        wavelength_indices : numpy.ndarray
            Array of wavelength indices
        target_spectrum : numpy.ndarray
            Array of absorbance values
        cut_from : int
            Wavelength index to start the analysis from
        ignore_abs_threshold : bool, optional
            Whether to ignore absorbance thresholds, defaults to False
        cut_to : int or False, optional
            Wavelength index to end the analysis at, defaults to False

        Returns
        -------
        numpy.ndarray
            Boolean mask indicating which indices to keep

        """
        threshold_interpolator = interpolate.interp1d(self.thresh_w_indices, self.thresh_as,
                                                      fill_value='extrapolate')

        if not ignore_abs_threshold:
            mask = np.logical_and(target_spectrum < threshold_interpolator(wavelength_indices),
                                  wavelength_indices > cut_from)
        else:
            mask = wavelength_indices > cut_from

        if cut_to:
            mask = np.logical_and(mask, wavelength_indices <= cut_to)

        mask = np.logical_and(mask,
                              target_spectrum > np.min(target_spectrum) + self.lower_limit_of_absorbance)


        return mask

    def mask_multispectrum(self, wavelength_indices, target_spectrum,
                           cut_from, ignore_abs_threshold=False, cut_to=False,
                           upper_limit_of_absorbance=0.95,
                           artefactogenic_upper_limit_of_absorbance=1.5):
        """
        Apply quality mask from `create_spectrum_mask()` to the input arrays of wavelength indices and target spectrum.
        See docstring of `create_spectrum_mask()` method for details on the masking criteria.
        """
        mask = create_spectrum_mask(
            wavelength_indices, target_spectrum, cut_from, cut_to,
            upper_limit_of_absorbance, artefactogenic_upper_limit_of_absorbance
        )

        return wavelength_indices[mask], target_spectrum[mask]


    def plot_calibrant_references(self,calibration_folder, calibrant_shortnames, calibrant_labels_on_the_plot):
        calibrants = self.load_dictionary_of_calibrants_from_files(calibrant_shortnames, calibration_folder,
                                                                   use_linear_calibration=True)
        for i, calibrant in enumerate(calibrants):
            if i < 10:
                linestyle = '-'
            else:
                linestyle = '--'
            xs = 220 + np.linspace(0, 400, 400)
            # xs = 220 + np.linspace(150, 400, 400)
            plt.plot(xs, calibrant['reference_interpolator'](xs - 220),
                     label=calibrant_labels_on_the_plot[calibrant_shortnames[i]],
                     linestyle=linestyle)
        plt.legend()
        plt.xlabel('Wavelength, nm')
        plt.ylabel('Absorbance')
        plt.xlim(220, 500)
        plt.ylim(0, 1.4)
        plt.show()


    def multispectrum_to_concentration(self, target_spectrum_inputs, calibration_folder, calibrant_shortnames,
                                       background_model_folder, dilution_factors,
                                       upper_limit_of_absorbance=1000, fig_filename='temp', do_plot=False,
                                       upper_bounds=[np.inf, np.inf], use_line=False, cut_from = 200, ignore_abs_threshold=False,
                                       cut_to = False, ignore_pca_bkg=False, return_errors=False,
                                       use_linear_calibration=True,
                                       return_report=False, sigma_of_absorbance=0.01,
                                       starting_concentration_dict=None, second_dilution_factor_bound_range=0.1,
                                       maximum_wavelength_offset=1.5,
                                       obey_stoichiometric_inequalities=True):
        """
        Determine component concentrations using multi-spectrum unmixing with dilution constraints.

        Performs quantitative analysis of complex chemical mixtures using multiple spectra
        of the same sample measured at different dilution factors. Provides superior accuracy
        and extended dynamic range compared to single-spectrum methods, especially if
        the spectrum of a mixture contains both high and low concentration components
        or both strongly absorbing and weakly absorbing bands.

        The algorithm fits a linear model to each spectrum:

        .. math::

            A_i(\lambda) = \sum_j \\frac{c_j}{d_i} R_j(\lambda + \Delta\lambda_i) + b_i + \sum_k w_{i,k} B_k(\lambda + \Delta\lambda_i)

        where:

        - :math:`A_i(λ)` is measured absorbance spectrum i at wavelength λ
        - :math:`c_j` is concentration of component j in undiluted sample
        - :math:`d_i` is dilution factor for spectrum i
        - :math:`R_j(λ)` is reference spectrum of component j
        - :math:`Δλ_i` is wavelength offset correction for spectrum i
        - :math:`b_i` is baseline offset for spectrum i
        - :math:`w_{i,k}` is weight of background PCA component k
        - :math:`B_k(λ)` is background PCA component k

        Parameters
        ----------
        target_spectrum_inputs : list of numpy.ndarray
            Input absorption spectra for the same sample at different dilutions.
            Each array has shape (n_wavelengths,) with background-subtracted absorbance values.
        calibration_folder : str
            Path to directory containing calibration data previously saved by `calibrator.py` workflow.
        calibrant_shortnames : list of str
            Short names of chemical components to include in the unmixing analysis.
        background_model_folder : str
            Path to directory containing PCA background model files.
        dilution_factors : list of float
            Dilution factors corresponding to each spectrum. First factor is fixed as reference, second one
            is going to be used as initial guess for fitting this dilution factor's value during unmixing.
        upper_limit_of_absorbance : float, optional
            Maximum absorbance value for inclusion in fitting. Points above this threshold are masked.
            Prevents fitting in regions where Beer-Lambert law breaks down or instrumental artifacts occur.
            Default is 1000, which practically means no limit. In our research we usually set it to 1.0 or 0.95.
        fig_filename : str, optional
            Base path for saving diagnostic plots. Default 'temp'.
        do_plot : bool, optional
            Whether to display interactive plots to the user during the fitting process. Default is False.
        upper_bounds : list of float, optional
            Upper concentration bounds for each calibrant. Default [np.inf, np.inf].
        use_line : bool, optional
            Whether to include linear baseline drift terms. Default False.
        cut_from : int, optional
            Wavelength index to start analysis from. Earlier wavelengths are ignored. It is counting points from the left
            edge of the spectrum. For example, in a typical nanodrop spectrum, the first point is at 220 nm, so if you set
            cut_from=5, it will start processing from 225 nm onwards.
        ignore_abs_threshold : bool, optional
            Whether to disable absorbance threshold masking. Default False.
        cut_to : int or False, optional
            Wavelelengths with index above this integer value are ignored. If None, then all wavelengths with indices
            above cut_from are used. Useful for excluding
            the long sections of almost zero absorbance at the red end of the spectrum, which are not contributing
            anything but noise to the calibration.
        ignore_pca_bkg : bool, optional
            Whether to disable PCA background component fitting. Default False.
        return_errors : bool, optional
            Whether to return uncertainty estimates. Default False. Must not be True if return_report is True.
        use_linear_calibration : bool, optional
            Whether to use linear calibration curves. Default True. If False, uses piecewise linear interpolation
            of the calibration data points.
        return_report : bool, optional
            Whether to return detailed fitting report. Default False. Must not be True if return_errors is True.
        sigma_of_absorbance : float, optional
            Standard deviation of absorbance measurements. Default 0.01.
        starting_concentration_dict : dict or None, optional
            Initial substrate concentrations. Only needed for the purpose of enforcing the stoichiometric constraints.
        second_dilution_factor_bound_range : float, optional
            Relative tolerance for fitting the second dilution factor. Default 0.1.
        maximum_wavelength_offset : float, optional
            Maximum allowed instrumental shift of wavelengths between the two spectra (nm). This is related to
            slight imprecision of the spectrophotometers, not to the spectral shifts of the true spectra of the mixtures.
            Default 1.5, which is adequate for NanoDrop and similar instruments. Reduce if using a more precise spectrophotometer.
        obey_stoichiometric_inequalities : bool, optional
            Whether to enforce stoichiometric constraints. Default True.

        Returns
        -------
        numpy.ndarray or tuple
            Array of fitted concentrations if return_report and return_errors are False.
            Tuple if return_errors or return_report is True: first element is concentrations,
            second element is either concentration errors or fitting report.
            Fitting report is a dictionary with detailed fitting information.
            It contains the keys starting with 'pcerr#' for the concentration errors of each calibrant,
            e.g. 'pcerr#dm35_9' for calibrant named 'dm35_9 .
            It further contains key 'rmse' for root-mean squared error of the fit.
            For each dilution number N, it has keys 'LB_pvalue_dil_N', 'LB_stat_dil_N',`dw_statistic_dil_N` for
            Ljung-Box p-value and statistic, and Durbon-Watson statistic, for the spectrum at that dilution,respectively.
            Ljung-Box statistic
            is computed at lag equal to the length of residuals divided by 5, which is largest value
            recommended by statsmodels package for Ljung-Box test. Durbin-Watson statistic is computed at lag 30 points,
            which means 30 nm in our case.

        Examples
        --------
        Two-spectrum analysis::

            >>> concentrations = sp.multispectrum_to_concentration(
            ...     target_spectrum_inputs=[spectrum_20x, spectrum_200x],
            ...     dilution_factors=[20, 200],
            ...     calibration_folder='calibration/',
            ...     calibrant_shortnames=['HRP01', 'methoxybenzaldehyde'],
            ...     background_model_folder='background/'
            ... )
        """

        # === INITIALIZATION AND DATA LOADING ===
        t0 = time.time()

        # Load calibration data for all calibrants (reference spectra and concentration-coefficient relationships)
        calibrants = self.load_dictionary_of_calibrants_from_files(calibrant_shortnames, calibration_folder,
                                                                   use_linear_calibration)
        print(f'N calibrants: {len(calibrants)}')

        # Load background spectrum - either shared background or average of calibrant backgrounds
        if ignore_pca_bkg:
            bkg_spectrum = np.mean(np.array([calibrant['bkg_spectrum'] for calibrant in calibrants]), axis=0)
        else:
            bkg_spectrum = np.load(background_model_folder + 'bkg_spectrum.npy')

        # Validate that all spectra have same wavelength grid as background
        for target_spectrum_input in target_spectrum_inputs:
            assert len(bkg_spectrum) == len(target_spectrum_input), \
                'Length of background spectrum is not the same as the length of the target spectrum.' \
                'This may be because the wavelengths are not aligned.'

        # === SPECTRAL PREPROCESSING ===
        # Subtract background from all target spectra
        wavelengths = bkg_spectrum[:, 0]
        target_spectra = [target_spectrum_input - bkg_spectrum[:, 1] for target_spectrum_input in
                          target_spectrum_inputs]
        wavelength_indices = np.arange(calibrants[0]['bkg_spectrum'].shape[0])

        # Apply quality masks to each spectrum - exclude problematic wavelength regions
        target_spectra_wavelength_indices_masked = []
        target_spectra_amplitudes_masked = []
        for i, target_spectrum in enumerate(target_spectra):
            target_spectrum_wavelengths_masked, target_spectrum_amplitudes_masked = self.mask_multispectrum(
                wavelength_indices, target_spectrum, cut_from, upper_limit_of_absorbance=upper_limit_of_absorbance,
                cut_to=cut_to)
            target_spectra_wavelength_indices_masked.append(target_spectrum_wavelengths_masked)
            target_spectra_amplitudes_masked.append(target_spectrum_amplitudes_masked)

            # Check if any usable data remains after masking
            if len(target_spectrum_wavelengths_masked) == 0:
                print(f'There is no data that is within mask for spectrum #{i}. Returning zeros.')
                return [0 for i in range(len(calibrant_shortnames))]

        # === DATA STRUCTURE PREPARATION FOR FITTING ===
        # Concatenate all masked spectra into single arrays for simultaneous fitting of both spectra
        combined_X = np.concatenate(target_spectra_wavelength_indices_masked)  # All wavelength indices
        combined_Y = np.concatenate(target_spectra_amplitudes_masked)  # All absorbance values

        # Setup measurement uncertainties for weighted fitting
        if not self.use_instrumental_sigmas:
            # Use constant uncertainty
            combo_sigmas = np.ones_like(combined_Y) * sigma_of_absorbance
        else:
            # Use wavelength and absorbance-dependent uncertainty model
            combo_sigmas = []
            for i, wavelength_index in enumerate(combined_X):
                wavelength_here = wavelengths[wavelength_index]
                absorbance_here = combined_Y[i]
                sigma_here_here = self.uncertainty_of_measured_absorbance(wavelength_here, absorbance_here)
                combo_sigmas.append(sigma_here_here)
            combo_sigmas = np.array(combo_sigmas)

        # Calculate indices for splitting combined arrays back into individual spectra
        indices_for_splitting = np.cumsum([len(target_spectrum_wavelengths_masked)
                                           for target_spectrum_wavelengths_masked in
                                           target_spectra_wavelength_indices_masked])[:-1]

        number_of_calibrants = len(calibrant_shortnames)
        number_of_spectra = len(target_spectrum_inputs)

        # Load PCA background components for modeling systematic background variations
        background_interpolators = self.load_background_interpolators(background_model_folder, ignore_pca_bkg,
                                                                      wavelength_indices, number_of_pca_components=1)

        # === DEFINE FITTING MODEL FUNCTIONS ===

        def preliminary_model_without_stoichiometric_inequalities(*args):
            """
            Core spectral model that predicts combined spectra from fitted parameters.

            This function implements the mathematical model that relates the measured spectra
            to the underlying chemical concentrations and instrumental parameters.

            Parameter structure in args:
            - args[0]: wavelength indices (combined_X)
            - args[1:number_of_calibrants+1]: concentrations of each calibrant in undiluted sample
            - args[number_of_calibrants+1:...]: dilution factors for spectra 2, 3, etc. (spectrum 1 factor is fixed)
            - next block: baseline offsets for each spectrum. Number of offsets = number_of_spectra
            - next block: PCA background weights for each spectrum.
            - final block: wavelength shift corrections for each spectrum. Number of shifts = number_of_spectra
            """

            # === PARSE FITTED PARAMETERS FROM ARGS ===
            xs = args[0]  # Combined wavelength indices for all spectra
            separate_spectra = np.split(xs, indices_for_splitting)  # Split back into individual spectrum indices

            # Extract calibrant concentrations in the undiluted parent sample
            calibrants_concentrations = args[1:number_of_calibrants + 1]

            # Extract dilution factors: first is fixed, others are fitted parameters
            dilutions_factors_here = [dilution_factors[0]] + list(
                args[number_of_calibrants + 1: number_of_calibrants + 1 + number_of_spectra - 1])
            assert len(dilutions_factors_here) == number_of_spectra

            # Extract baseline offsets for each spectrum (accounts for instrumental drift)
            offsets = args[number_of_calibrants + 1 + number_of_spectra - 1:
                           number_of_calibrants + 1 + number_of_spectra - 1 + number_of_spectra]

            # Extract PCA background component weights for each spectrum
            bkg_pca_weights = args[number_of_calibrants + 1 + number_of_spectra - 1 + number_of_spectra:
                                   number_of_calibrants + 1 + number_of_spectra - 1 + number_of_spectra + number_of_spectra]

            # Extract wavelength calibration offsets for each spectrum (accounts for instrumental wavelength shifts)
            wavelength_offsets = args[
                                 number_of_calibrants + 1 + number_of_spectra - 1 + number_of_spectra + number_of_spectra:
                                 number_of_calibrants + 1 + number_of_spectra - 1 + number_of_spectra + number_of_spectra + number_of_spectra]

            # === PREDICT EACH SPECTRUM SEPARATELY ===
            separate_predicted_spectra = []
            for spectrum_index, wavelength_indices_for_this_spectrum in enumerate(separate_spectra):

                # Apply wavelength calibration offset to correct for instrumental wavelength shifts between spectra
                wavelengths_corrected = wavelength_indices_for_this_spectrum + wavelength_offsets[spectrum_index]

                # Calculate diluted concentrations for this specific spectrum
                dilution_factor_for_this_spectrum = dilutions_factors_here[spectrum_index]
                calibrants_concentrations_for_this_spectrum = [conc / dilution_factor_for_this_spectrum
                                                               for conc in calibrants_concentrations]

                # Convert concentrations to spectral scaling coefficients using calibration curves
                calibrants_coeffs_for_this_spectrum = [
                    np.asscalar(calibrants[i]['concentration_to_coeff_interpolator'](
                        calibrants_concentrations_for_this_spectrum[i]))
                    for i in range(number_of_calibrants)
                ]

                # Initialize predicted spectrum
                predicted_spectrum = np.zeros_like(wavelengths_corrected)

                # Sum contributions from all calibrants (core Beer-Lambert law implementation)
                for i in range(number_of_calibrants):
                    predicted_spectrum += (calibrants_coeffs_for_this_spectrum[i] *
                                           calibrants[i]['reference_interpolator'](wavelengths_corrected))

                # Add systematic contributions: baseline offset + PCA background component
                predicted_spectrum += (offsets[spectrum_index] +
                                       background_interpolators[0](wavelengths_corrected) * bkg_pca_weights[
                                           spectrum_index])

                separate_predicted_spectra.append(predicted_spectrum)

            # Concatenate all predicted spectra to match the structure of measured data
            combined_Y = np.concatenate(separate_predicted_spectra)
            return combined_Y

        def model_with_stoichiometric_inequalities(*args):
            """
            Enhanced model that adds stoichiometric constraints via penalty method.

            This function wraps the core spectral model and adds soft constraints to prevent
            solutions that violate chemical stoichiometry (e.g., more product than possible
            given starting material amounts).
            """

            # Extract calibrant concentrations from fitted parameters
            calibrants_concentrations = args[1:number_of_calibrants + 1]

            # Get base model prediction
            combined_Y = preliminary_model_without_stoichiometric_inequalities(*args)

            # Add stoichiometric penalty if starting concentrations are provided
            if starting_concentration_dict is not None:
                # Calculate penalty for violating stoichiometric constraints
                stoich_penalization_of_cost = self.stoich_cost(calibrants_concentrations, calibrant_shortnames,
                                                               starting_concentration_dict)

                # Apply penalty by modifying the last two data points (this creates artificial data points that
                # are driven away from zero when stoichiometry is violated, increasing the fitting residuals)
                combined_Y[-2] += stoich_penalization_of_cost * combo_sigmas[
                    -2] / self.uncertainty_of_stoichiometric_overspending_ratio
                combined_Y[-1] -= stoich_penalization_of_cost * combo_sigmas[
                    -1] / self.uncertainty_of_stoichiometric_overspending_ratio

            return combined_Y

        # === SETUP FITTING PARAMETERS AND BOUNDS ===
        bounds, p0, x_scale = self.prepare_initial_guess_and_bounds_and_xscale(
            calibrant_shortnames, dilution_factors, ignore_pca_bkg, maximum_wavelength_offset,
            number_of_calibrants, number_of_spectra, obey_stoichiometric_inequalities,
            second_dilution_factor_bound_range, starting_concentration_dict)

        # === PERFORM FITTING ===

        # = THE REASONS BEHIND THE FOLLOWING LOGIC =
        # if stoichiometric inequalities must be obeyed, try to fit the model with them, using the previous fit as a
        # starting point.
        # Because the scipy.optimize.curve_fit is implemented in a way that exceeding the maximum number of function
        # evaluations throws an error, we try to fit the model with relaxed tolerances and smaller number of function
        # evaluations first. And only go to larger number of function evaluations if it fails. On average, this saves
        # computational resources,and increases precision.

        # First fit: preliminary fitting without stoichiometric constraints
        popt, pcov = curve_fit(preliminary_model_without_stoichiometric_inequalities, combined_X, combined_Y, method='trf',
                               p0=p0, bounds=bounds, sigma=combo_sigmas, absolute_sigma=True,
                               maxfev=100000, ftol=1e-15, xtol=1e-15, gtol=1e-15, verbose=1, x_scale=x_scale)

        # Second fit: add stoichiometric constraints if requested
        # Uses hierarchical fitting strategy with progressively relaxed tolerances if needed
        if obey_stoichiometric_inequalities:
            print('prelim done')
            try:
                # Try strict tolerances first
                popt, pcov = curve_fit(model_with_stoichiometric_inequalities, combined_X, combined_Y,
                                       p0=popt, bounds=bounds, sigma=combo_sigmas, absolute_sigma=True,
                                       maxfev=100, ftol=1e-15, xtol=1e-15, gtol=1e-15, verbose=1,
                                       x_scale=x_scale)
            except RuntimeError:
                # Fall back to progressively relaxed tolerances if fitting fails
                print(f'RuntimeError, hopefully max_nfev')
                print('Trying again with 1e-12 tolerances')
                try:
                    popt, pcov = curve_fit(model_with_stoichiometric_inequalities, combined_X, combined_Y, method='trf',
                                           p0=popt, bounds=bounds, sigma=combo_sigmas, absolute_sigma=True,
                                           maxfev=100, ftol=1e-12, xtol=1e-12, gtol=1e-12, verbose=1,
                                           x_scale=x_scale)
                except RuntimeError:
                    print(f'RuntimeError, hopefully max_nfev')
                    print('Trying again with 1e-10 tolerances')
                    try:
                        popt, pcov = curve_fit(model_with_stoichiometric_inequalities, combined_X, combined_Y, method='trf',
                                               p0=popt, bounds=bounds, sigma=combo_sigmas, absolute_sigma=True,
                                               maxfev=100, ftol=1e-10, xtol=1e-10, gtol=1e-10, verbose=1,
                                               x_scale=x_scale)
                    except RuntimeError:
                        print(f'RuntimeError, hopefully max_nfev')
                        print('Trying again with 1e-6 tolerances')
                        popt, pcov = curve_fit(model_with_stoichiometric_inequalities, combined_X, combined_Y, method='trf',
                                               p0=popt, bounds=bounds, sigma=combo_sigmas, absolute_sigma=True,
                                               maxfev=100, ftol=1e-6, xtol=1e-6, gtol=1e-6, verbose=1,
                                               x_scale=x_scale)

        # === EXTRACT AND REPORT RESULTS ===

        perr = np.sqrt(np.diag(pcov))  # Parameter uncertainties from covariance matrix
        concentrations_here = popt[0:number_of_calibrants]  # Final fitted concentrations

        # Display stoichiometric analysis if constraints were applied
        if obey_stoichiometric_inequalities:
            required_subs = self.product_concentrations_to_required_substrates(concentrations_here,
                                                                               calibrant_shortnames)
            os_string = ''
            for s in self.substrates:
                overspending_ratio = required_subs[s] / starting_concentration_dict[s]
                string_here = f'{s} osr: {overspending_ratio - 1:.1%}\n'
                os_string += string_here
            os_string = os_string[:-1]
            print(os_string)
        else:
            os_string = ''

        # Extract fitted instrumental parameters for diagnostics
        fitted_dilution_factors = popt[number_of_calibrants: number_of_calibrants + number_of_spectra - 1]
        fitted_offsets = popt[
                         number_of_calibrants + number_of_spectra - 1: number_of_calibrants + number_of_spectra - 1 + number_of_spectra]
        fitted_wavelength_offsets = popt[
                                    number_of_calibrants + number_of_spectra - 1 + number_of_spectra + number_of_spectra:
                                    number_of_calibrants + number_of_spectra - 1 + number_of_spectra + number_of_spectra + number_of_spectra]

        # Log fitting results for diagnostics
        logging.debug(f'Fitted wavelength offsets: {fitted_wavelength_offsets}')
        logging.debug('Fitted concentrations:', concentrations_here)
        logging.debug('Fitted dilution factors:', fitted_dilution_factors)
        logging.debug('Fitted offsets:', fitted_offsets)
        logging.debug('Popt: ', popt)
        logging.debug('p0: ', p0)

        # === GENERATE FITTING DIAGNOSTICS ===

        # Calculate final model prediction and fitting statistics
        predicted_combined_Y = preliminary_model_without_stoichiometric_inequalities(combined_X, *popt)

        fit_report = dict()
        concentration_errors = []
        for calibrant_id, calibrant_shortname in enumerate(calibrant_shortnames):
            fit_report[f'pcerr#{calibrant_shortname}'] = perr[calibrant_id]
            concentration_errors.append(perr[calibrant_id])

        fit_report['rmse'] = np.sqrt(np.mean((predicted_combined_Y - combined_Y) ** 2))
        fit_report['maxresidual'] = np.max(np.abs(predicted_combined_Y - combined_Y))
        fit_report['fitted_dilution_factor_2'] = fitted_dilution_factors[0]

        # Extract background component weights for reporting
        weights_of_background_components = popt[number_of_calibrants + number_of_spectra - 1 + number_of_spectra:
                                                number_of_calibrants + number_of_spectra - 1 + number_of_spectra + number_of_spectra]
        print(f'weights_of_background_components: {weights_of_background_components}')

        # Statistical analysis of fitting residuals
        separate_predicted_spectra = np.split(predicted_combined_Y, indices_for_splitting)
        separate_sigmas = np.split(combo_sigmas, indices_for_splitting)
        for spectrum_index in range(number_of_spectra):
            residuals_here = separate_predicted_spectra[spectrum_index] - target_spectra_amplitudes_masked[
                spectrum_index]
            # Record Ljung-Box test statistics for residual autocorrelation
            lag = len(residuals_here) // 5
            lb_df = sm.stats.acorr_ljungbox(residuals_here, lags=[lag])
            if isinstance(lb_df, pd.DataFrame):
                if len(lb_df) == 1:
                    fit_report[f'LB_pvalue_dil_{spectrum_index}'] = lb_df.loc[lag, 'lb_pvalue']
                    fit_report[f'LB_stat_dil_{spectrum_index}'] = lb_df.loc[lag, 'lb_stat']
            # if lb_df is a tuple
            elif isinstance(lb_df, tuple):
                fit_report[f'LB_pvalue_dil_{spectrum_index}'] = lb_df[1][0]
                fit_report[f'LB_stat_dil_{spectrum_index}'] = lb_df[0][0]
            else:
                raise ValueError(f"Unexpected type of lb_df: {type(lb_df)}. Expected DataFrame or tuple. "
                                 f"Maybe something wrong with the statsmodels version?")
            if len(residuals_here) > 60:
                lag = 30 # points, which in our case means 30 nm
                fit_report[f'dw_statistic_dil_{spectrum_index}'] = sm.stats.stattools.durbin_watson(residuals_here[::lag])
            else:
                fit_report[f'dw_statistic_dil_{spectrum_index}'] = 2

        print(fit_report)


        # === VISUALIZATION ===

        # Generate diagnostic plots showing fit quality and component contributions
        self.plot_result_of_multispectrum_unmixing(background_interpolators, calibrant_shortnames, combined_X, do_plot,
                                                   fig_filename, indices_for_splitting,
                                                   model_with_stoichiometric_inequalities, number_of_calibrants,
                                                   number_of_spectra, os_string, popt, separate_predicted_spectra,
                                                   separate_sigmas, target_spectra_amplitudes_masked,
                                                   target_spectra_wavelength_indices_masked, target_spectrum_inputs,
                                                   weights_of_background_components)

        print(f'Time spent for this unmixing: {time.time() - t0} seconds.')

        # === RETURN RESULTS ===

        if return_report:
            return concentrations_here, fit_report
        elif return_errors:
            return concentrations_here, concentration_errors
        else:
            return concentrations_here

    def prepare_initial_guess_and_bounds_and_xscale(self, calibrant_shortnames, dilution_factors, ignore_pca_bkg,
                                                    maximum_wavelength_offset, number_of_calibrants, number_of_spectra,
                                                    obey_stoichiometric_inequalities,
                                                    second_dilution_factor_bound_range, starting_concentration_dict):
        """
        Prepare optimization parameters for multi-spectrum fitting with scipy.optimize.curve_fit.

        This function constructs the initial parameter guess (p0), parameter bounds, and characteristic
        scales (x_scale) for the nonlinear least-squares optimization. The parameters are organized
        in a specific order that matches how the model functions parse their arguments.

        The parameter vector structure is:
        1. Calibrant concentrations (number_of_calibrants parameters)
        2. Dilution factors for spectra 2, 3, etc. (number_of_spectra - 1 parameters, spectrum 1 is reference)
        3. Baseline offsets for each spectrum (number_of_spectra parameters)
        4. PCA background component weights for each spectrum (number_of_spectra parameters)
        5. Wavelength calibration offsets for each spectrum (number_of_spectra parameters)

        When stoichiometric constraints are enabled, concentration upper bounds are calculated based
        on starting material availability and reaction stoichiometry to prevent unphysical solutions.

        Parameters
        ----------
        calibrant_shortnames : list of str
            Names of chemical components being fitted.
        dilution_factors : list of float
            Dilution factors for each spectrum. First factor is fixed as reference.
        ignore_pca_bkg : bool
            If True, constrains PCA background weights to near-zero values.
        maximum_wavelength_offset : float
            Maximum allowed wavelength shift between spectra (nm).
        number_of_calibrants : int
            Number of chemical components being fitted.
        number_of_spectra : int
            Number of spectra being fitted simultaneously.
        obey_stoichiometric_inequalities : bool
            If True, enforces stoichiometric constraints on concentrations.
        second_dilution_factor_bound_range : float
            Relative tolerance for dilution factor fitting (e.g., 0.1 = ±10%).
        starting_concentration_dict : dict or None
            Starting substrate concentrations for stoichiometric calculations.

        Returns
        -------
        bounds : tuple
            (lower_bounds, upper_bounds) for scipy.optimize.curve_fit bounds parameter.
        p0 : list
            Initial parameter guesses for scipy.optimize.curve_fit p0 parameter.
        x_scale : list
            Characteristic parameter scales for scipy.optimize.curve_fit x_scale parameter.

        Notes
        -----
        The x_scale parameter helps the optimizer by providing characteristic scales for each
        parameter type (concentrations ~mM, dilution factors ~10-1000, offsets ~0.01, etc.).
        This normalization improves convergence for parameters with very different magnitudes.
        For details, see
        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit
        for documentation of `scipy.optimize.curve_fit` and its parameters.

        """

        # Initialize parameter arrays
        p0 = []  # Initial parameter guesses
        lower_bounds = []  # Lower bounds for each parameter
        upper_bounds = []  # Upper bounds for each parameter
        x_scale = []  # Characteristic scales for parameter normalization

        # === CALCULATE STOICHIOMETRIC CONCENTRATION LIMITS ===
        # If stoichiometry is enforced, calculate maximum possible concentration for each calibrant
        # based on available starting materials and reaction stoichiometry
        if obey_stoichiometric_inequalities:
            calibrant_concentration_upper_bounds = []
            for i, substance_for_fitting in enumerate(calibrant_shortnames):
                limits_here = []

                # Check each substrate to find the limiting reagent for this product
                for s in self.substrates:
                    # Get stoichiometric coefficient for this substrate in this product's formation
                    stoich_coeff = self.df_stoich.loc[self.df_stoich['Names'] == substance_for_fitting, s].values[0]
                    if stoich_coeff == 0:
                        continue  # This substrate is not used for this product

                    # Calculate maximum product concentration limited by this substrate
                    limit_by_this_substrate = starting_concentration_dict[s] / stoich_coeff
                    limits_here.append(limit_by_this_substrate)

                # Use the most restrictive (minimum) limit across all substrates
                calibrant_concentration_upper_bounds.append(min(limits_here))
            print(f'Stoichiometric concentration limits: {calibrant_concentration_upper_bounds}')

        # === PARAMETER BLOCK 1: CALIBRANT CONCENTRATIONS ===
        # Add one concentration parameter per calibrant
        for i in range(number_of_calibrants):
            p0.append(1e-7)  # Initial guess: 0.1 μM (typical starting point)
            x_scale.append(1e-3)  # Characteristic scale: 1 mM (typical concentration range)
            lower_bounds.append(0)  # Concentrations cannot be negative

            if obey_stoichiometric_inequalities:
                # Set upper bound based on stoichiometric limits, with 2x safety factor
                upper_bounds.append(max([2e-7, 2 * calibrant_concentration_upper_bounds[i]]))
            else:
                # No stoichiometric constraints - allow unlimited concentrations
                upper_bounds.append(np.inf)

        # === PARAMETER BLOCK 2: DILUTION FACTORS ===
        # Add dilution factors for spectra 2, 3, etc. (spectrum 1 is fixed reference)
        for i in range(number_of_spectra - 1):
            nominal_dilution = dilution_factors[i + 1]  # Target dilution factor

            p0.append(nominal_dilution)  # Initial guess: nominal value
            x_scale.append(nominal_dilution)  # Scale: same order of magnitude as value

            # Allow small deviations around nominal dilution factor to account for pipetting errors
            tolerance = second_dilution_factor_bound_range  # e.g., 0.1 = ±10%
            lower_bounds.append(nominal_dilution * (1 - tolerance))
            upper_bounds.append(nominal_dilution * (1 + tolerance))

        # === PARAMETER BLOCK 3: BASELINE OFFSETS ===
        # Add baseline offset correction for each spectrum (accounts for instrumental drift)
        for i in range(number_of_spectra):
            p0.append(0)  # Initial guess: no offset
            x_scale.append(0.01)  # Scale: typical absorbance offset magnitude
            lower_bounds.append(-np.inf)  # Offsets can be positive or negative
            upper_bounds.append(np.inf)

        # === PARAMETER BLOCK 4: PCA BACKGROUND WEIGHTS ===
        # Add PCA background component weights for modeling systematic background variations
        if ignore_pca_bkg:
            # Effectively disable PCA background by constraining weights to near-zero
            max_bkg_pca_weight = 1e-12
        else:
            # Allow significant PCA background contributions
            max_bkg_pca_weight = 0.5

        for i in range(number_of_spectra):
            p0.append(0)  # Initial guess: no background contribution
            x_scale.append(max_bkg_pca_weight)  # Scale: maximum allowed weight
            lower_bounds.append(-1 * max_bkg_pca_weight)  # Weights can be positive or negative
            upper_bounds.append(max_bkg_pca_weight)

        # === PARAMETER BLOCK 5: WAVELENGTH OFFSETS ===
        # Add wavelength calibration offsets to correct for small instrumental wavelength shifts
        for i in range(number_of_spectra):
            p0.append(0)  # Initial guess: no wavelength shift
            x_scale.append(1)  # Scale: 1 nm (typical shift magnitude)
            lower_bounds.append(-1 * maximum_wavelength_offset)  # e.g., ±1.5 nm for NanoDrop
            upper_bounds.append(maximum_wavelength_offset)

        # Package bounds in format expected by scipy.optimize.curve_fit
        bounds = (lower_bounds, upper_bounds)

        return bounds, p0, x_scale


    def plot_result_of_multispectrum_unmixing(self, background_interpolators, calibrant_shortnames, combined_X, do_plot,
                                              fig_filename, indices_for_splitting,
                                              model_with_stoichiometric_inequalities, number_of_calibrants,
                                              number_of_spectra, os_string, popt, separate_predicted_spectra,
                                              separate_sigmas, target_spectra_amplitudes_masked,
                                              target_spectra_wavelength_indices_masked, target_spectrum_inputs,
                                              weights_of_background_components):
        fig1, axs = plt.subplots(len(target_spectrum_inputs), 1, figsize=(10, 10), sharex=True)
        for spectrum_index in range(number_of_spectra):
            axs[spectrum_index].plot(220 + target_spectra_wavelength_indices_masked[spectrum_index],
                                     target_spectra_amplitudes_masked[spectrum_index], color='red',
                                     label='Data', alpha=0.7)
            axs[spectrum_index].fill_between(x=220 + target_spectra_wavelength_indices_masked[spectrum_index],
                                             y1=target_spectra_amplitudes_masked[spectrum_index] - separate_sigmas[
                                                 spectrum_index],
                                             y2=target_spectra_amplitudes_masked[spectrum_index] + separate_sigmas[
                                                 spectrum_index],
                                             color='gold', alpha=0.15)
            axs[spectrum_index].plot(220 + target_spectra_wavelength_indices_masked[spectrum_index],
                                     separate_predicted_spectra[spectrum_index], color='black', label='Fit', alpha=0.7)
        for calibrant_index in range(len(calibrant_shortnames)):
            if calibrant_index <= 9:
                linestyle_here = '-'  # solid line
            else:
                linestyle_here = '--'  # dashed line
            cpopt = popt.copy()
            for i in range(number_of_calibrants):
                if i != calibrant_index:
                    cpopt[i] = 0
            predicted_combined_Y = model_with_stoichiometric_inequalities(combined_X, *cpopt)
            separate_predicted_spectra = np.split(predicted_combined_Y, indices_for_splitting)
            for spectrum_index in range(number_of_spectra):
                axs[spectrum_index].plot(220 + target_spectra_wavelength_indices_masked[spectrum_index],
                                         separate_predicted_spectra[spectrum_index],
                                         label=calibrant_shortnames[calibrant_index], linestyle=linestyle_here)
        for spectrum_index in range(number_of_spectra):
            # plot background
            axs[spectrum_index].plot(220 + target_spectra_wavelength_indices_masked[spectrum_index],
                                     background_interpolators[0](
                                         target_spectra_wavelength_indices_masked[spectrum_index]) *
                                     weights_of_background_components[spectrum_index],
                                     label='Bkg. PC1', linestyle=':')

        axs[0].legend()
        plt.xlabel('Wavelength, nm')
        plt.ylabel('Absorbance')
        axs[0].set_title(os_string)

        fig1.savefig(f"{fig_filename}.png")
        if do_plot:
            plt.show()
        else:
            plt.close(fig1)
            plt.close('all')
            plt.clf()

    def load_background_interpolators(self, background_model_folder, ignore_pca_bkg,
                                      wavelength_indices, number_of_pca_components=1):
        if not ignore_pca_bkg:
            background_interpolators = [interpolate.interp1d(wavelength_indices,
                                                             np.load(background_model_folder + f'component_{i}.npy'),
                                                             fill_value='extrapolate')
                                        for i in range(number_of_pca_components)]
        else:
            background_interpolators = [interpolate.interp1d(wavelength_indices,
                                                             np.ones_like(wavelength_indices),
                                                             fill_value='extrapolate')
                                        for i in range(number_of_pca_components)]
        return background_interpolators

    def load_dictionary_of_calibrants_from_files(self, calibrant_shortnames, calibration_folder,
                                                 use_linear_calibration):
        calibrants = []
        for calibrant_shortname in calibrant_shortnames:
            dict_here = dict()
            dict_here['coeff_to_concentration_interpolator'], dict_here['reference_interpolator'], dict_here[
                'bkg_spectrum'] = \
                self.load_calibration_for_one_calibrant(calibrant_shortname, calibration_folder,
                                                        use_line_fit=use_linear_calibration,
                                                        do_savgol_filtering=False,
                                                        returned_interpolator_direction='coeff_to_concentration')
            dict_here['concentration_to_coeff_interpolator'], _, _ = \
                self.load_calibration_for_one_calibrant(
                    calibrant_shortname, calibration_folder, use_line_fit=use_linear_calibration,
                    do_savgol_filtering=False,
                    returned_interpolator_direction='concentration_to_coeff')
            calibrants.append(dict_here.copy())
        return calibrants

    def uncertainty_of_measured_absorbance(self, wavelength, absorbance, lower_threshold_of_sigma=0.005):
        """
        Calculate instrument-specific uncertainty of absorption spectra measurements.

        Provides quantitative uncertainty estimates using empirical error models based on
        bivariate interpolation of residual data from calibration measurements.

        Parameters
        ----------
        wavelength : float
            Wavelength in nm for uncertainty evaluation.
        absorbance : float
            Absorbance value for uncertainty evaluation.
        lower_threshold_of_sigma : float, optional
            Minimum uncertainty value to prevent unrealistic precision claims. Default 0.005.

        Returns
        -------
        float
            Estimated standard deviation of the absorbance measurement in absorbance units.

        Notes
        -----
        The uncertainty model σ(wavelength, absorbance) is created from systematic residual
        analysis of calibration measurements and accounts for both deviations from the linearity of
        Beer-Lambert law and noise of the spectrophotometer.
        """
        variance = self.sigma_interpolator(wavelength, absorbance)[0][0]
        if variance < lower_threshold_of_sigma**2:
            variance = lower_threshold_of_sigma**2
        return np.sqrt(variance)

    def product_concentrations_to_required_substrates(self, concentrations, calibrant_shortnames):
        """
        Calculate the required substrate concentrations for given product concentrations,
        based on stoichiometric coefficients.

        Parameters
        ----------
        concentrations : list
            List of product concentrations
        calibrant_shortnames : list
            List of short names of the products

        Returns
        -------
        dict
            Dictionary mapping substrate names to required concentrations
        """
        dict_of_substrate_concentrations = {s: 0 for s in self.substrates}
        for i, substance_for_fitting in enumerate(calibrant_shortnames):
            for s in self.substrates:
                # find the cell in self.df_stoich where Name is equal to substance_for_fitting and column is s
                dict_of_substrate_concentrations[s] += concentrations[i] * self.df_stoich.loc[
                    self.df_stoich['Names'] == substance_for_fitting, s].values[0]
        return dict_of_substrate_concentrations

    def stoich_cost(self, concentrations, calibrant_shortnames, starting_concentrations_dict):
        """
        Calculate the stoichiometric cost (penalization) for a set of concentrations.

        This is used to enforce stoichiometric constraints in the spectral unmixing algorithm.

        Parameters
        ----------
        concentrations : list
            List of product concentrations
        calibrant_shortnames : list
            List of short names of the products
        starting_concentrations_dict : dict
            Dictionary mapping substrate names to starting concentrations

        Returns
        -------
        float
            Stoichiometric cost (penalization value)
        """
        required_subs = self.product_concentrations_to_required_substrates(concentrations, calibrant_shortnames)
        final_penalization = 0
        for s in self.substrates:
            if starting_concentrations_dict[s] > 0:
                overspending_ratio = required_subs[s] / starting_concentrations_dict[s]
                final_penalization += relu_step((overspending_ratio - 1))

        return final_penalization


    ####################### OBSOLETE METHOD RETAINED ONLY FOR BACKWARD COMPATIBILITY WITH OLDER CODE.
    ####################### FOR NEW CODE, USE METHODS IN robowski.uv_vis_absorption_spectroscopy.calibrator INSTEAD
    def construct_reference_for_calibrant(self, calibrant_shortname,
                                          calibration_folder, ref_concentration,
                                          do_plot=True, lower_limit_of_absorbance=0.05, do_reference_refinements=True):
        """
        OBSOLETE METHOD RETAINED ONLY FOR BACKWARD COMPATIBILITY WITH OLDER CODE.
        FOR NEW CODE, USE METHODS IN robowski.uv_vis_absorption_spectroscopy.calibrator

        Construct a reference spectrum for a calibrant and save it for later use.

        This method creates a reference spectrum, optionally refines it, and establishes
        the relationship between concentration and absorption coefficient. The results are
        saved to disk for later use in concentration calculations.

        Parameters
        ----------
        calibrant_shortname : str
            Short name of the calibrant
        calibration_folder : str
            Path to the folder containing calibration data
        ref_concentration : float
            Reference concentration for the calibrant
        do_plot : bool, optional
            Whether to display plots during processing, defaults to True
        lower_limit_of_absorbance : float, optional
            Lower limit for absorbance values, defaults to 0.05
        do_reference_refinements : bool, optional
            Whether to perform reference spectrum refinements, defaults to True

        Returns
        -------
        tuple
            (coeff_to_concentration_interpolator, reference_interpolator, bkg_spectrum)
        """
        create_folder_unless_it_exists(calibration_folder + 'references')
        create_folder_unless_it_exists(calibration_folder + 'background')
        create_folder_unless_it_exists(calibration_folder + f'references/{calibrant_shortname}')
        calibration_sequence_df = pd.read_csv(calibration_folder + 'calibration_sequence_dataframe.csv')
        one_calibrant_df = calibration_sequence_df.loc[calibration_sequence_df['shortname'] == calibrant_shortname]

        # make sure that only one well for this calibrant has zero concentration. Otherwise it's weird.
        assert one_calibrant_df.loc[one_calibrant_df['concentration'] == 0].shape[0] == 1
        bkg_row = one_calibrant_df.loc[one_calibrant_df['concentration'] == 0].iloc[0]
        bkg_spectrum = self.load_msp_by_id(
            plate_folder=calibration_folder + f"plate-{bkg_row['plate_id']:04d}/",
            well_id=bkg_row['well_id'])

        def load_spectrum_by_df_row(row):
            spectrum = self.load_msp_by_id(
                plate_folder=calibration_folder + f"plate-{row['plate_id']:04d}/",
                well_id=row['well_id'])
            spectrum[:, 1] -= bkg_spectrum[:, 1]
            return spectrum

        # make sure that only one well for this calibrant has concentration equal to ref_concentration
        assert one_calibrant_df.loc[one_calibrant_df['concentration'] == ref_concentration].shape[0] == 1
        ref_spectrum = load_spectrum_by_df_row(
            one_calibrant_df.loc[one_calibrant_df['concentration'] == ref_concentration].iloc[0])[:, 1]
        ref_spectrum -= np.mean(ref_spectrum[-100:])
        if do_plot:
            plt.plot(ref_spectrum)
            plt.title('Ref spectrum')
            plt.show()

        all_spectra = [self.load_msp_by_id(
            plate_folder=calibration_folder + f"plate-{row['plate_id']:04d}/",
            well_id=row['well_id']) for index, row in one_calibrant_df.iterrows()]

        wavelength_indices = np.arange(ref_spectrum.shape[0])
        reference_interpolator = interpolate.interp1d(wavelength_indices, ref_spectrum, fill_value='extrapolate')

        thresh_w_indices = [0, 25, 127, 2000]
        thresh_as = [0.67, 0.75, 1.6, 1.6]
        threshold_interpolator = interpolate.interp1d(thresh_w_indices, thresh_as, fill_value='extrapolate')

        concentrations = sorted(one_calibrant_df['concentration'].to_list())

        def refine_reference(cut_from, row, do_plot=True, use_first_n_points_after_masking=100):
            create_folder_unless_it_exists(calibration_folder + f'references/{calibrant_shortname}/refinements')
            target_spectrum = load_spectrum_by_df_row(row)[:, 1]
            mask_containing_entire_tail = np.logical_and(target_spectrum < threshold_interpolator(wavelength_indices),
                                                         wavelength_indices > cut_from)
            first_index_where_data_is_not_ignored = np.argmax(mask_containing_entire_tail)
            mask = np.logical_and(mask_containing_entire_tail,
                                  wavelength_indices < first_index_where_data_is_not_ignored + use_first_n_points_after_masking)

            def func(xs, a, b):
                return a * reference_interpolator(xs) + b

            p0 = (0.5, 0)
            bounds = ([0, -np.inf], [np.inf, np.inf])
            popt, pcov = curve_fit(func, wavelength_indices[mask], target_spectrum[mask],
                                   p0=p0, bounds=bounds)
            # sigma=noise_std*np.ones_like(target_spectrum),
            # absolute_sigma=True)
            perr = np.sqrt(np.diag(pcov))
            slope = popt[0]
            slope_error = perr[0]

            new_ref_spectrum = np.copy(ref_spectrum)
            new_ref_spectrum[mask_containing_entire_tail] = (target_spectrum[mask_containing_entire_tail] - popt[
                1]) / slope
            new_ref_spectrum -= new_ref_spectrum[-1]

            ### PLOTTING
            fig1 = plt.figure(1)
            plt.plot(target_spectrum, label='data', color='C0', alpha=0.5)

            mask_illustration = np.ones_like(target_spectrum) * 4
            mask_illustration[mask] = 0
            plt.fill_between(x=wavelength_indices, y1=0, y2=mask_illustration, color='yellow', alpha=0.3,
                             label='Data is ignored')
            plt.plot(func(wavelength_indices, *popt), color='r', label='fit', alpha=0.5)
            plt.plot(func(wavelength_indices, popt[0], 0), color='C1', label='reference', alpha=0.5)
            plt.ylim(np.min((func(wavelength_indices, *popt)[mask_containing_entire_tail])),
                     np.max((func(wavelength_indices, *popt)[mask_containing_entire_tail])) * 2)
            plt.title(
                f"conc {row['concentration']}, well {row['well_id']}, plate {row['plate_id']:04d}")
            plt.legend()
            fig1.savefig(
                calibration_folder + f"references/{calibrant_shortname}/refinements/{row['concentration']}_refinement_fit.png",
                dpi=300)
            if do_plot:
                plt.show()
            else:
                plt.clf()


            fig2 = plt.figure(2)
            plt.title(
                f"Refined reference, well {row['concentration']}, well {row['well_id']}, plate {row['plate_id']:04d} was used")
            plt.plot(new_ref_spectrum - np.min(new_ref_spectrum), color='black', alpha=0.5, label='new reference')
            plt.plot(ref_spectrum - np.min(new_ref_spectrum), color='C0', alpha=0.5, label='old reference')
            plt.yscale('log')
            plt.legend()
            fig2.savefig(
                calibration_folder + f"references/{calibrant_shortname}/refinements/{row['concentration']}_refined_result.png",
                dpi=300)
            if do_plot:
                plt.show()
            else:
                plt.clf()

            return new_ref_spectrum, interpolate.interp1d(wavelength_indices, new_ref_spectrum,
                                                          fill_value='extrapolate')

        if do_reference_refinements:
            for concentration in concentrations:
                if concentration <= ref_concentration:
                    # Right tail of absorption band is better only in spectra having higher concentrations than the reference
                    continue
                df_row_here = one_calibrant_df.loc[one_calibrant_df['concentration'] == concentration].iloc[0]
                ref_spectrum, reference_interpolator = refine_reference(cut_from=250, row=df_row_here, do_plot=False)

        create_folder_unless_it_exists(calibration_folder + f'references/{calibrant_shortname}/concentration_fits')
        # cut_from = 115
        cut_from=200
        coeffs = []
        coeff_errs = []
        for concentration in concentrations:
            if concentration == 0:
                coeffs.append(0)
                coeff_errs.append(0)
                continue

            df_row_here = one_calibrant_df.loc[one_calibrant_df['concentration'] == concentration].iloc[0]
            target_spectrum = load_spectrum_by_df_row(df_row_here)[:, 1]
            mask = np.logical_and(target_spectrum < threshold_interpolator(wavelength_indices),
                                  wavelength_indices > cut_from)
            mask = np.logical_and(mask, target_spectrum > np.min(target_spectrum) + lower_limit_of_absorbance)

            def func(xs, a, b):
                return a * reference_interpolator(xs) + b

            p0 = (concentration / ref_concentration, 0)
            bounds = ([-1e-10, -np.inf], [np.inf, np.inf])
            popt, pcov = curve_fit(func, wavelength_indices[mask], target_spectrum[mask],
                                   p0=p0, bounds=bounds)
            # sigma=noise_std*np.ones_like(target_spectrum),
            # absolute_sigma=True)
            perr = np.sqrt(np.diag(pcov))
            slope = popt[0]
            slope_error = perr[0]
            coeffs.append(slope)
            coeff_errs.append(slope_error)

            fig1 = plt.figure(1)
            plt.plot(target_spectrum, label='data', color='C0', alpha=0.5)
            mask_illustration = np.ones_like(target_spectrum) * np.max(target_spectrum)
            mask_illustration[mask] = 0
            plt.fill_between(x=wavelength_indices, y1=0, y2=mask_illustration, color='yellow', alpha=0.3,
                             label='ignored (masked) data')
            plt.plot(func(wavelength_indices, *popt), color='r', label='fit', alpha=0.5)
            plt.plot(func(wavelength_indices, popt[0], 0), color='C1', label='reference', alpha=0.5)
            plt.ylim(-0.3,
                     np.max((func(wavelength_indices, *popt)[mask])) * 2)
            plt.title(
                f"conc {df_row_here['concentration']}, well {df_row_here['well_id']}, plate {df_row_here['plate_id']:04d}")
            plt.legend()
            fig1.savefig(
                calibration_folder + f"references/{calibrant_shortname}/concentration_fits/{df_row_here['concentration']}_fit.png")
            if do_plot:
                plt.show()
            else:
                plt.clf()

        fig3 = plt.figure(3)
        plt.loglog(coeffs, concentrations, 'o-')
        plt.xlabel('Fit coefficients')
        plt.ylabel('Concentrations, mol/liter')
        fig3.savefig(calibration_folder + f"references/{calibrant_shortname}/concentration-vs-coeff.png", dpi=300)
        if do_plot:
            plt.show()
        else:
            plt.clf()

        coeff_to_concentration_interpolator = interpolate.interp1d(coeffs, concentrations,
                                                                   fill_value='extrapolate')

        np.save(calibration_folder + f'references/{calibrant_shortname}/bkg_spectrum.npy', bkg_spectrum)
        np.save(calibration_folder + f'background//bkg_spectrum.npy', bkg_spectrum)
        np.save(calibration_folder + f'references/{calibrant_shortname}/ref_spectrum.npy', ref_spectrum)
        np.save(calibration_folder + f'references/{calibrant_shortname}/interpolator_coeffs.npy', np.array(coeffs))
        np.save(calibration_folder + f'references/{calibrant_shortname}/interpolator_concentrations.npy',
                concentrations)

        return coeff_to_concentration_interpolator, reference_interpolator, bkg_spectrum


def relu_step(x):
    if x <= 0:
        return 0
    else:
        return x


def plot_differential_absorbances_for_plate(craic_exp_name,
                                            wavelength,
                                            ref_wavelengths,
                                            ):
    """
    Plots the difference between absorbance at the target wavelength and the mean absorbance at reference wavelengths
    from ref_wavelength list.

    Parameters
    ----------
    craic_exp_name: str
        Name of the folder with CRAIC microspectrometer measurements.
    wavelength
        Target wavelength at which the absorbance is calculated.
    ref_wavelengths
        List of reference wavelengths. Mean absorbance at these wavelengths is subtracted from the absorbance at the
        target wavelength.

    Returns
    -------
    diff: np.array
        Array of differential absorbances.
    """
    sp = SpectraProcessor(folder_with_correction_dataset=repo_data_path + 'uv_vis_absorption_spectroscopy/microspectrometer-calibration/'
                                                         '2022-12-01/interpolator-dataset/')
    craic_folder = data_folder + 'craic_microspectrometer_measurements/absorbance/'
    sp.show_all_spectra(craic_folder + craic_exp_name + '/')
    plt.show()
    diff = sp.get_absorbance_at_single_wavelength_for_one_plate(craic_folder + craic_exp_name + '/',
                                                                wavelength=wavelength,
                                                                ref_wavelengths=ref_wavelengths)
    diluted_indices = [i + j for i in [9, 27, 45] for j in range(9)]
    undiluted_indices = [i + j for i in [0, 18, 36] for j in range(9)]
    diff = diff[diluted_indices]
    print(f'rel.std {np.std(diff) / np.mean(diff)}')
    plt.plot(diff)
    plt.xlabel('Vial ID')
    plt.ylabel(f'Absorbance at {wavelength} nm minus absorbance at wavelengths {ref_wavelengths} nm')
    plt.title(f'{craic_exp_name}.\nRel. STD: {np.std(diff) / np.mean(diff)}')
    plt.show()
    return diff


if __name__ == '__main__':
    pass


